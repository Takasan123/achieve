{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 畳み込みニューラルネットワークの実践\n",
    "## AIF_sprint13_cnn2\n",
    "この課題の目的  \n",
    "・スクラッチを通してCNNの基礎を理解する   \n",
    "・基本的なCNNのキーワードを学習する   \n",
    "・初期の有名なCNNモデルを知る   \n",
    "\n",
    "【目的としないこと】   \n",
    "実用的なCNNモデルに関する知識の習得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44800, 1, 28, 28) (14000, 1, 28, 28) (11200, 1, 28, 28)\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (14000, 10) [[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "# MNISTの読み込み\n",
    "mnist_dir = \"/Users/andoutakaaki/DIC_study/sprint9/mnist_data/\"\n",
    "mnist = fetch_mldata('MNIST original', data_home=mnist_dir)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.2)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# 正解（ラベル）をint型にしておく\n",
    "y_train = y_train.astype(np.int)\n",
    "y_test = y_test.astype(np.int)\n",
    "y_val = y_val.astype(np.int)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_val = X_val.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_val /= 255\n",
    "\n",
    "# -- 正解をone-hot表現に --\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test = enc.transform(y_test[:, np.newaxis])\n",
    "y_val = enc.transform(y_val[:, np.newaxis])\n",
    "\n",
    "# 28×28に変形\n",
    "# チャンネル方向の軸は用意:(n_samples, n_channels, height, width)のNCHW\n",
    "X_train = X_train.reshape(44800,1, 28,28)\n",
    "X_test = X_test.reshape(14000,1, 28,28)\n",
    "X_val = X_val.reshape(11200,1, 28,28)\n",
    "\n",
    "n_train = X_train.shape[0]  # 訓練データのサンプル数\n",
    "n_test = X_test.shape[0]  # テストデータのサンプル数\n",
    "n_val = X_val.shape[0]  # valデータのサンプル数\n",
    "\n",
    "print(X_train.shape,X_test.shape,X_val.shape)\n",
    "print(y_train,y_test.shape,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 各設定値 --\n",
    "img_h = 28  # 入力画像の高さ\n",
    "img_w = 28  # 入力画像の幅\n",
    "img_ch = 1  # 入力画像のチャンネル数\n",
    "\n",
    "wb_width = 0.1  # 重みとバイアスの広がり具合\n",
    "eta = 0.01  # 学習係数\n",
    "epoch = 10\n",
    "batch_size = 1\n",
    "interval = 10  # 経過の表示間隔\n",
    "n_sample = 44800  # 誤差計測のサンプル数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- im2col --\n",
    "def im2col(images, flt_h, flt_w, out_h, out_w, stride, pad):\n",
    "   \n",
    "    n_bt, n_ch, img_h, img_w = images.shape\n",
    "    \n",
    "    img_pad = np.pad(images, [(0,0), (0,0), (pad, pad), (pad, pad)], \"constant\")\n",
    "    cols = np.zeros((n_bt, n_ch, flt_h, flt_w, out_h, out_w))\n",
    "\n",
    "    for h in range(flt_h):\n",
    "        h_lim = h + stride*out_h\n",
    "        for w in range(flt_w):\n",
    "            w_lim = w + stride*out_w\n",
    "            cols[:, :, h, w, :, :] = img_pad[:, :, h:h_lim:stride, w:w_lim:stride]\n",
    "\n",
    "    cols = cols.transpose(1, 2, 3, 0, 4, 5).reshape(n_ch*flt_h*flt_w, n_bt*out_h*out_w)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- col2im --\n",
    "def col2im(cols, img_shape, flt_h, flt_w, out_h, out_w, stride, pad):\n",
    " \n",
    "    n_bt, n_ch, img_h, img_w = img_shape\n",
    "    \n",
    "    cols = cols.reshape(n_ch, flt_h, flt_w, n_bt, out_h, out_w, ).transpose(3, 0, 1, 2, 4, 5)\n",
    "    images = np.zeros((n_bt, n_ch, img_h+2*pad+stride-1, img_w+2*pad+stride-1))\n",
    "    \n",
    "    for h in range(flt_h):\n",
    "        h_lim = h + stride*out_h\n",
    "        for w in range(flt_w):\n",
    "            w_lim = w + stride*out_w\n",
    "            images[:, :, h:h_lim:stride, w:w_lim:stride] += cols[:, :, h, w, :, :]\n",
    "\n",
    "    return images[:, :, pad:img_h+pad, pad:img_w+pad]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 畳み込み層 --\n",
    "class ConvLayer:\n",
    "    \n",
    "    # n_bt:バッチサイズ, x_ch:入力チャンネル数, x_h:入力画像高さ, x_w:入力画像幅\n",
    "    # n_flt:フィルタ数, flt_h:フィルタ高さ, flt_w:フィルタ幅\n",
    "    # stride:ストライド幅, pad:パディング幅\n",
    "    # y_ch:出力チャンネル数, y_h:出力高さ, y_w:出力幅\n",
    "    \n",
    "    def __init__(self, x_ch, x_h, x_w, n_flt, flt_h, flt_w, stride, pad):\n",
    "\n",
    "        # パラメータをまとめる\n",
    "        self.params = (x_ch, x_h, x_w, n_flt, flt_h, flt_w, stride, pad)\n",
    "        \n",
    "        # フィルタとバイアスの初期値\n",
    "        self.w = wb_width * np.random.randn(n_flt, x_ch, flt_h, flt_w)\n",
    "        self.b = wb_width * np.random.randn(1, n_flt)\n",
    "        \n",
    "        # 出力画像のサイズ\n",
    "        self.y_ch = n_flt  # 出力チャンネル数\n",
    "        self.y_h = (x_h - flt_h + 2*pad) // stride + 1  # 出力高さ\n",
    "        self.y_w = (x_w - flt_w + 2*pad) // stride + 1  # 出力幅\n",
    " \n",
    "        # AdaGrad用\n",
    "        self.h_w = np.zeros((n_flt, x_ch, flt_h, flt_w)) + 1e-8\n",
    "        self.h_b = np.zeros((1, n_flt)) + 1e-8\n",
    "        \n",
    "    def forward(self, x):\n",
    "        n_bt = x.shape[0] \n",
    "        x_ch, x_h, x_w, n_flt, flt_h, flt_w, stride, pad = self.params\n",
    "        y_ch, y_h, y_w = self.y_ch, self.y_h, self.y_w\n",
    "        \n",
    "        # 入力画像とフィルタを行列に変換\n",
    "        self.cols = im2col(x, flt_h, flt_w, y_h, y_w, stride, pad)\n",
    "        self.w_col = self.w.reshape(n_flt, x_ch*flt_h*flt_w)\n",
    "        \n",
    "        # 出力の計算: 行列積、バイアスの加算、活性化関数\n",
    "        u = np.dot(self.w_col, self.cols).T + self.b\n",
    "        self.u = u.reshape(n_bt, y_h, y_w, y_ch).transpose(0, 3, 1, 2)\n",
    "        self.y = np.where(self.u <= 0, 0, self.u)\n",
    "    \n",
    "    def backward(self, grad_y):\n",
    "        n_bt = grad_y.shape[0]\n",
    "        x_ch, x_h, x_w, n_flt, flt_h, flt_w, stride, pad = self.params\n",
    "        y_ch, y_h, y_w = self.y_ch, self.y_h, self.y_w\n",
    "        \n",
    "        # delta\n",
    "        delta = grad_y * np.where(self.u <= 0, 0, 1)\n",
    "        delta = delta.transpose(0,2,3,1).reshape(n_bt*y_h*y_w, y_ch)\n",
    "        \n",
    "        # フィルタとバイアスの勾配\n",
    "        grad_w = np.dot(self.cols, delta)\n",
    "        self.grad_w = grad_w.T.reshape(n_flt, x_ch, flt_h, flt_w)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        \n",
    "        # 入力の勾配\n",
    "        grad_cols = np.dot(delta, self.w_col)\n",
    "        x_shape = (n_bt, x_ch, x_h, x_w)\n",
    "        self.grad_x = col2im(grad_cols.T, x_shape, flt_h, flt_w, y_h, y_w, stride, pad)\n",
    "        \n",
    "    def update(self, eta):\n",
    "        self.h_w += self.grad_w * self.grad_w\n",
    "        self.w -= eta / np.sqrt(self.h_w) * self.grad_w\n",
    "        \n",
    "        self.h_b += self.grad_b * self.grad_b\n",
    "        self.b -= eta / np.sqrt(self.h_b) * self.grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- プーリング層 --\n",
    "class PoolingLayer:\n",
    "    \n",
    "    # n_bt:バッチサイズ, x_ch:入力チャンネル数, x_h:入力画像高さ, x_w:入力画像幅\n",
    "    # pool:プーリング領域のサイズ, pad:パディング幅\n",
    "    # y_ch:出力チャンネル数, y_h:出力高さ, y_w:出力幅\n",
    "    \n",
    "    def __init__(self, x_ch, x_h, x_w, pool, pad):\n",
    "        \n",
    "        # パラメータをまとめる\n",
    "        self.params = (x_ch, x_h, x_w, pool, pad)\n",
    "        \n",
    "        # 出力画像のサイズ\n",
    "        self.y_ch = x_ch  # 出力チャンネル数\n",
    "        self.y_h = x_h//pool if x_h%pool==0 else x_h//pool+1  # 出力高さ\n",
    "        self.y_w = x_w//pool if x_w%pool==0 else x_w//pool+1  # 出力幅\n",
    "        \n",
    "    def forward(self, x):\n",
    "        n_bt = x.shape[0] \n",
    "        x_ch, x_h, x_w, pool, pad = self.params\n",
    "        y_ch, y_h, y_w = self.y_ch, self.y_h, self.y_w\n",
    "        \n",
    "        # 入力画像を行列に変換\n",
    "        cols = im2col(x, pool, pool, y_h, y_w, pool, pad)\n",
    "        cols = cols.T.reshape(n_bt*y_h*y_w*x_ch, pool*pool)\n",
    "        \n",
    "        # 出力の計算: Maxプーリング\n",
    "        y = np.max(cols, axis=1)\n",
    "        self.y = y.reshape(n_bt, y_h, y_w, x_ch).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        # 最大値のインデックスを保存\n",
    "        self.max_index = np.argmax(cols, axis=1)\n",
    "    \n",
    "    def backward(self, grad_y):\n",
    "        n_bt = grad_y.shape[0] \n",
    "        x_ch, x_h, x_w, pool, pad = self.params\n",
    "        y_ch, y_h, y_w = self.y_ch, self.y_h, self.y_w\n",
    "        \n",
    "        # 出力の勾配の軸を入れ替え\n",
    "        grad_y = grad_y.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        # 行列を作成し、各列の最大値であった要素にのみ出力の勾配を入れる\n",
    "        grad_cols = np.zeros((pool*pool, grad_y.size))\n",
    "        grad_cols[self.max_index.reshape(-1), np.arange(grad_y.size)] = grad_y.reshape(-1) \n",
    "        grad_cols = grad_cols.reshape(pool, pool, n_bt, y_h, y_w, y_ch)\n",
    "        grad_cols = grad_cols.transpose(5,0,1,2,3,4) \n",
    "        grad_cols = grad_cols.reshape( y_ch*pool*pool, n_bt*y_h*y_w)\n",
    "\n",
    "        # 入力の勾配\n",
    "        x_shape = (n_bt, x_ch, x_h, x_w)\n",
    "        self.grad_x = col2im(grad_cols, x_shape, pool, pool, y_h, y_w, pool, pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 全結合層の継承元 --\n",
    "class BaseLayer:\n",
    "    def __init__(self, n_upper, n):\n",
    "        self.w = wb_width * np.random.randn(n_upper, n)\n",
    "        self.b = wb_width * np.random.randn(n)\n",
    "\n",
    "        self.h_w = np.zeros(( n_upper, n)) + 1e-8\n",
    "        self.h_b = np.zeros(n) + 1e-8\n",
    "        \n",
    "    def update(self, eta):\n",
    "        self.h_w += self.grad_w * self.grad_w\n",
    "        self.w -= eta / np.sqrt(self.h_w) * self.grad_w\n",
    "        \n",
    "        self.h_b += self.grad_b * self.grad_b\n",
    "        self.b -= eta / np.sqrt(self.h_b) * self.grad_b\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 全結合 中間層 --\n",
    "class MiddleLayer(BaseLayer):\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.u = np.dot(x, self.w) + self.b\n",
    "        self.y = np.where(self.u <= 0, 0, self.u)\n",
    "    \n",
    "    def backward(self, grad_y):\n",
    "        delta = grad_y * np.where(self.u <= 0, 0, 1)\n",
    "        \n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        \n",
    "        self.grad_x = np.dot(delta, self.w.T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 全結合 出力層 --\n",
    "class OutputLayer(BaseLayer):     \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        u = np.dot(x, self.w) + self.b\n",
    "        self.y = np.exp(u)/np.sum(np.exp(u), axis=1).reshape(-1, 1)\n",
    "\n",
    "    def backward(self, t):\n",
    "        delta = self.y - t\n",
    "        \n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        \n",
    "        self.grad_x = np.dot(delta, self.w.T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 各層の初期化 --\n",
    "cl_1 = ConvLayer(img_ch, img_h, img_w, 10, 3, 3, 1, 1)\n",
    "pl_1 = PoolingLayer(cl_1.y_ch, cl_1.y_h, cl_1.y_w, 2, 0)\n",
    "\n",
    "n_fc_in = pl_1.y_ch * pl_1.y_h * pl_1.y_w\n",
    "ml_1 = MiddleLayer(n_fc_in, 100)\n",
    "ol_1 = OutputLayer(100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 順伝播 --\n",
    "def forward_propagation(x):\n",
    "    n_bt = x.shape[0]\n",
    "    \n",
    "    images = x.reshape(n_bt, img_ch, img_h, img_w)\n",
    "    cl_1.forward(images)\n",
    "    pl_1.forward(cl_1.y)\n",
    "    \n",
    "    fc_input = pl_1.y.reshape(n_bt, -1)   \n",
    "    ml_1.forward(fc_input)\n",
    "    ol_1.forward(ml_1.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 逆伝播 --\n",
    "def backpropagation(t):\n",
    "    n_bt = t.shape[0]\n",
    "    \n",
    "    ol_1.backward(t)\n",
    "    ml_1.backward(ol_1.grad_x)\n",
    "    \n",
    "    grad_img = ml_1.grad_x.reshape(n_bt, pl_1.y_ch, pl_1.y_h, pl_1.y_w)\n",
    "    pl_1.backward(grad_img)\n",
    "    cl_1.backward(pl_1.grad_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 重みとバイアスの更新 --\n",
    "def uppdate_wb():\n",
    "    cl_1.update(eta)\n",
    "    ml_1.update(eta)\n",
    "    ol_1.update(eta)\n",
    "\n",
    "# -- 誤差を計算 --\n",
    "def get_error(t, batch_size):\n",
    "    return -np.sum(t * np.log(ol_1.y + 1e-7)) / batch_size # 交差エントロピー誤差\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- サンプルを順伝播 --\n",
    "def forward_sample(inp, correct, n_sample):\n",
    "    index_rand = np.arange(len(correct))\n",
    "    np.random.shuffle(index_rand) \n",
    "    index_rand = index_rand[:n_sample]\n",
    "    x = inp[index_rand, :]\n",
    "    t = correct[index_rand, :]\n",
    "    forward_propagation(x)\n",
    "    return x, t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0/10 Error_train:2.3526994692760317 Error_test:0.73578834791586\n"
     ]
    }
   ],
   "source": [
    "# -- 誤差の記録用 --\n",
    "train_error_x = []\n",
    "train_error_y = []\n",
    "test_error_x = []\n",
    "test_error_y = []\n",
    "\n",
    "# -- 学習と経過の記録 --\n",
    "n_batch = n_train // batch_size\n",
    "for i in range(epoch):\n",
    "\n",
    "    # -- 誤差の計測 -- \n",
    "    x, t = forward_sample(X_train, y_train, n_sample)\n",
    "    error_train = get_error(t, n_sample)\n",
    "    \n",
    "    x, t = forward_sample(X_test, y_test, n_sample) \n",
    "    error_test = get_error(t, n_sample)\n",
    "    \n",
    "    # -- 誤差の記録 -- \n",
    "    train_error_x.append(i)\n",
    "    train_error_y.append(error_train) \n",
    "    test_error_x.append(i)\n",
    "    test_error_y.append(error_test) \n",
    "    \n",
    "    # -- 経過の表示 --\n",
    "    if i%interval == 0:\n",
    "        print(\"Epoch:\" + str(i) + \"/\" + str(epoch),\n",
    "              \"Error_train:\" + str(error_train),\n",
    "              \"Error_test:\" + str(error_test))\n",
    "        \n",
    "        # -- 学習 -- \n",
    "    index_rand = np.arange(n_train)\n",
    "    np.random.shuffle(index_rand)   \n",
    "    for j in range(n_batch):\n",
    "        \n",
    "        mb_index = index_rand[j*batch_size : (j+1)*batch_size]\n",
    "        x = X_train[mb_index, :]\n",
    "        t = y_train[mb_index, :]\n",
    "\n",
    "        forward_propagation(x)\n",
    "        backpropagation(t)        \n",
    "        uppdate_wb() \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3X+cXHV97/HXZ2Z/JjtDfm0yQxJI\nCD9mAwiEVVG0CKIS20rvQyja0h8RH3lg9UqrtkVtVbBarK29IlSKGtRblVp/XewFUZRqvRYhYORH\nNoFI+bEmIZsA2d0k+2NmPvePOTM7uzubnSQze3b2vJ+PxzzmzDnfc+azA5v3nvme8/2auyMiIgIQ\nC7sAERGZPRQKIiJSolAQEZEShYKIiJQoFEREpEShICIiJQoFEREpUSiIiEiJQkFEREqawi7gSC1Z\nssRXrVoVdhkiIg3lwQcf3OvundO1a7hQWLVqFZs3bw67DBGRhmJmT1fTTl8fiYhIiUJBRERKFAoi\nIlLScH0KIiJHYnR0lN7eXoaGhsIuZUa0tbWxYsUKmpubj2p/hYKIzGm9vb0kEglWrVqFmYVdTl25\nO/v27aO3t5fVq1cf1TH09ZGIzGlDQ0MsXrx4zgcCgJmxePHiYzorUiiIyJwXhUAoOtafNTKhsH33\nAH97Vw+Dw9mwSxERmbUiEwrPPn+Qf/7xk2zf3R92KSISEfv27ePss8/m7LPPJpVKsXz58tLrkZGR\nqo6xYcMGtm/fXudKx0SmozmTTgDQs2uAc09cFHI1IhIFixcvZsuWLQB85CMfoaOjg/e9733j2rg7\n7k4sVvlv9Ntuu63udZaLzJnC8gXtJNqa2KYzBREJ2Y4dOzjjjDO4+uqrWbduHbt27WLjxo10d3dz\n+umnc/3115favupVr2LLli1ks1kWLFjAtddey1lnncUrXvEK9uzZU/PaInOmYGZ0pZJs2zUQdiki\nEpLrvvsYW3fW9g/Dtccn+fBvn37E+23dupXbbruNW265BYAbbriBRYsWkc1mufDCC7nssstYu3bt\nuH3279/PBRdcwA033MB73vMeNm3axLXXXluTn6MoMmcKUPgKadvuAfJ5D7sUEYm4NWvW8NKXvrT0\n+mtf+xrr1q1j3bp19PT0sHXr1kn7tLe3s379egDOPfdcnnrqqZrXFZkzBYBMKsng8NP8+sVDrFw0\nL+xyRGSGHc1f9PUyf/780vITTzzBpz/9ae6//34WLFjAlVdeWfFeg5aWltJyPB4nm6391ZSRO1MA\n6NmlfgURmT36+/tJJBIkk0l27drF3XffHVotkTpTOG1ZAjPYtnuA15+eCrscEREA1q1bx9q1aznj\njDM46aSTOP/880Orxdwb6/v17u5uP5ZJdl7zyXtZe3ySf/r9c2tYlYjMVj09PXR1dYVdxoyq9DOb\n2YPu3j3dvpH6+ggK/Qo9ugJJRKSi6IVCOsFT+w5wcETDXYiITBS9UEglcYfHnxsMuxQRkVkncqGw\nNp0EYJuuQBIRmSRyobBiYTvzW+Js261+BRGRiSIXCrGYcVoqwVadKYiITBK5UADIpJNs29VPo12O\nKyKNpRZDZwNs2rSJ3bt317HSMZG6ea2oK5Xgqz/Psmv/EMcvaA+7HBGZo6oZOrsamzZtYt26daRS\n9b/pNpqhUOxs3t2vUBCRUHzpS1/i5ptvZmRkhFe+8pXcdNNN5PN5NmzYwJYtW3B3Nm7cyLJly9iy\nZQtXXHEF7e3t3H///ePGQKq1SIbCqamxCXcuyiwLuRoRmTF3XQu7H6ntMVNnwvobjmiXRx99lG9/\n+9v87Gc/o6mpiY0bN3L77bezZs0a9u7dyyOPFGp88cUXWbBgAZ/5zGe46aabOPvss2tbewWRDIVk\nWzMrFrZrYDwRCcU999zDAw88QHd3YdSJQ4cOsXLlSt7whjewfft2rrnmGt74xjfy+te/fsZri2Qo\nQOEmNl2WKhIxR/gXfb24O29729v46Ec/Omnbww8/zF133cWNN97IN7/5TW699dYZrS2SVx8BdKUT\nPNk3yNBoLuxSRCRiLr74Yr7+9a+zd+9eoHCV0jPPPENfXx/uzuWXX851113HQw89BEAikWBgYGb+\niI3smUJXOkneYceeQc5YflzY5YhIhJx55pl8+MMf5uKLLyafz9Pc3Mwtt9xCPB7nqquuwt0xMz7x\niU8AsGHDBt7+9rfPSEdz5IbOLnqyb5CL/uHHfPKyl3B598oaVCYis5GGzi7Q0NnTOHHxfNqaYxpG\nW0SkTGRDIR4zTluWYNtuXYEkIlJUt1Aws5Vmdq+Z9ZjZY2Z2TYU2ZmY3mtkOM3vYzNbVq55KChPu\naLgLkbkuSr/jx/qz1vNMIQu81927gPOAd5rZ2glt1gOnBI+NwGfrWM8kXekELxwcpW9geCbfVkRm\nUFtbG/v27YtEMLg7+/bto62t7aiPUberj9x9F7ArWB4wsx5gObC1rNmlwJe98F/rPjNbYGbpYN+6\nywTDXfTsHmBp8ug/RBGZvVasWEFvby99fX1hlzIj2traWLFixVHvPyOXpJrZKuAc4OcTNi0Hni17\n3Rusm5lQKA130c8Fp3bOxFuKyAxrbm5m9erVYZfRMOre0WxmHcA3gT9194m9ulZhl0nneGa20cw2\nm9nmWqb9gnktpI9r0yxsIiKBuoaCmTVTCISvuPu3KjTpBcpvElgB7JzYyN1vdfdud+/u7KztX/SZ\nVELDXYiIBOp59ZEBXwB63P1TUzS7A/jD4Cqk84D9M9WfUNSVTrJjzyAj2fxMvq2IyKxUzz6F84E/\nAB4xsy3Bug8AJwC4+y3AncAbgR3AQWBDHeupKJNOks07O/YMsvb45Ey/vYjIrFLPq49+SuU+g/I2\nDryzXjVUoyvobN62u1+hICKRF9k7motWL5lPS1NM/QoiIigUaIrHOHVZhybcERFBoQBowh0RkSKF\nAoXLUvsGhtk7qOEuRCTaFAoULksF2KZhtEUk4hQKjA13oWG0RSTqFArA4o5WliZaNeGOiESeQiGQ\nSSd1piAikadQCHSlEjzx3CCjOQ13ISLRpVAIZNIJRnJ5/nvvgbBLEREJjUIhkEkFE+7oJjYRiTCF\nQmBNZwfNcdNNbCISaQqFQEtTjDWdHZpwR0QiTaFQpiud1GWpIhJpCoUymVSC3f1DvHBgJOxSRERC\noVAokykOd6F+BRGJKIVCma60hrsQkWhTKJTp7Ghl8fwWDYwnIpGlUChjZmTSCXp0piAiEaVQmCCT\nSrJ99wC5vIddiojIjFMoTJBJJRjO5nlqn4a7EJHoUShMoAl3RCTKFAoTnLy0g3jMdAWSiESSQmGC\ntuY4Jy2Zr4HxRCSSFAoVZDTchYhElEKhgkwqwa9fPET/0GjYpYiIzCiFQgVrg87m7RruQkQiRqFQ\nQaY43IX6FUQkYhQKFaSSbRzX3sxW9SuISMQoFCowMzKphC5LFZHIUShMoStdGO4ir+EuRCRCFApT\n6EonODiS49kXDoZdiojIjFEoTCGTKlyBpPsVRCRKFApTOHVZAjN0Z7OIRErdQsHMNpnZHjN7dIrt\nrzGz/Wa2JXh8qF61HI32ljirF89XZ7OIREpTHY/9ReAm4MuHafOf7v5bdazhmHSlkzy6c3/YZYiI\nzJi6nSm4+0+A5+t1/JmQSSV4et9BDgxnwy5FRGRGhN2n8Aoz+6WZ3WVmp4dcyySZ4nAXz6mzWUSi\nIcxQeAg40d3PAj4DfGeqhma20cw2m9nmvr6+GSswkyoMd6HOZhGJitBCwd373X0wWL4TaDazJVO0\nvdXdu929u7Ozc8ZqXLGwnURrk2ZhE5HICC0UzCxlZhYsvyyoZV9Y9VRiZmTSGu5CRKKjblcfmdnX\ngNcAS8ysF/gw0Azg7rcAlwHvMLMscAh4i7vPujElMqkk3/nFr3F3ggwTEZmz6hYK7v7WabbfROGS\n1Vktk04wcF+WX794iBUL54VdjohIXYV99dGsp+EuRCRKFArTOC2lCXdEJDoUCtPoaG3ixMXz2Kap\nOUUkAhQKVcikEvToCiQRiQCFQhUyqSRP7T3AoZFc2KWIiNSVQqEKXekEeYfHNdyFiMxxCoUqFK9A\n0k1sIjLXKRSqcMKiecxrieuyVBGZ8xQKVYjFjNNSGu5CROY+hUKVMqkkPbsGmIUjcYiI1IxCoUpd\n6QT7D42yu38o7FJEROpm2lAws7iZfXImipnNSp3N6lcQkTls2lBw9xxwrkV8iNBMOphwR/0KIjKH\nVTtK6i+A/2Nm/wYcKK5092/VpapZKNnWzPIF7TpTEJE5rdpQWERhApyLytY5EJlQgEK/gqbmFJG5\nrKpQcPcN9S6kEWRSSe7d3sfQaI625njY5YiI1FxVVx+Z2Qoz+7aZ7TGz58zsm2a2ot7FzTaZdIJc\n3tmxZzDsUkRE6qLaS1JvA+4AjgeWA98N1kVKV7o43IX6FURkbqo2FDrd/TZ3zwaPLwKddaxrVlq1\neD6tTTFNuCMic1a1obDXzK4M7lmIm9mVFDqeIyUeDHehy1JFZK6qNhTeBvwusBvYBVwWrIucTCqh\n4S5EZM6q6o5m4M3u/iZ373T3pe7+O+7+9AzUN+t0pZM8f2CEvsHhsEsREam5au9ovnQGamkIGu5C\nROayar8++n9mdpOZvdrM1hUfda1slsqkCsNdaBhtEZmLqr2j+ZXB8/Vl65zxdzhHwsL5LaSSbZpw\nR0TmpGlDwcxiwGfd/eszUE9DyGi4CxGZo6rpU8gD75qBWhpGVzrJr/oGGcnmwy5FRKSmqu1T+IGZ\nvc/MVprZouKjrpXNYplUgtGc8+ReDXchInNLtX0KxXsS3lm2zoGTaltOYygNd7FroHQ1kojIXFDt\nKKmr611II1m9ZD4t8Rg9u/r5nXOWh12OiEjNHPbrIzP7i7Llyyds+3i9iprtmuMxTl7aQY8GxhOR\nOWa6PoW3lC2/f8K2S2pcS0PpSic1MJ6IzDnThYJNsVzpdaR0pRPsGRhmn4a7EJE5ZLpQ8CmWK70e\nx8w2BZPyPDrFdjOzG81sh5k93Gh3SBc7mLfrKyQRmUOmC4WzzKzfzAaAlwTLxddnTrPvFzn8V0zr\ngVOCx0bgs1XWPCtk0oXhLrbqKyQRmUMOe/WRux/1RMTu/hMzW3WYJpcCX/bCGNT3mdkCM0u7+66j\nfc+ZtKSjlSUdrZqFTUTmlGpvXquH5cCzZa97g3UNoyud0MB4IjKnhBkKlTqqK/ZTmNlGM9tsZpv7\n+vrqXFb1utJJHn9ukGxOw12IyNwQZij0AivLXq8AdlZq6O63unu3u3d3ds6eqaEzqQQj2TxP7TsQ\ndikiIjURZijcAfxhcBXSecD+RulPKCpegbRVw2iLyBxRt1Aws68B/wWcZma9ZnaVmV1tZlcHTe4E\nngR2AJ8D/qRetdTLmqXzaYqZbmITkTmj2gHxjpi7v3Wa7c74AfYaTmtTnJOXdugKJBGZM8L8+mhO\nyKQSOlMQkTlDoXCMMukkO/cPsf/gaNiliIgcM4XCMcqkCnc29+h+BRGZAxQKx2hswh2Fgog0PoXC\nMVqaaGXR/BZ1NovInKBQOEZmRiaV0IQ7IjInKBRqIJNK8vjuAXL5w44mLiIy6ykUaiCTTnBoNMfT\nGu5CRBqcQqEGuoLhLtSvICKNTqFQA6cs6yBmugJJRBqfQqEG2prjnNTZoc5mEWl4CoUayaQS9OhM\nQUQanEKhRrrSSXpfOET/kIa7EJHGpVCoka50YbiLx/UVkog0MIVCjRQn3FG/gog0MoVCjaSPayPZ\n1qQrkESkoUUnFA7shR//HeRzdTm8mZFJJ9XZLCINLTqh8OR/wL0fgy1fqdtbdKUSbN89QF7DXYhI\ng4pOKJzxZlh5HvzwehjaX5e36EonOTCSo/eFQ3U5vohIvUUnFMxg/Q1jXyPVQSZd7GzWV0gi0pii\nEwoAx58D51wJP78F9j5R88OfuqwDM9i2S1cgiUhjilYoALz2Q9DUDnd/sOaHntfSxKrF89XZLCIN\nK3qh0LEULvgLeOJueOIHNT98JpVgm74+EpEGFb1QAHj51bBoDXzv/ZCr7bAUXekkTz9/kAPD2Zoe\nV0RkJkQzFJpa4A0fh31PwP2fq+mhM6kE7vD4c+pXEJHGE81QADj1DbDmtfAfwRVJNdKV1oQ7ItK4\nohsKZnDJ38LoAfjR39TssMsXtNPR2qTOZhFpSNENBYDO0+BlG+HBL8Kuh2tyyFjMOC2V0GWpItKQ\noh0KULgSad6iQqez12Z4iq50gp7d/XiNjiciMlMUCu0L4aK/gqd/Clu/U5NDZlJJBoay7Nw/VJPj\niYjMFIUCwLo/gmVnwPf/GkaPfdyi4oQ7GkZbRBqNQgEgFodLboD9z8LPPnPMhzt1WSEU1NksIo1G\noVC0+tWw9lL4z0/B/t5jOlSirZmVi9o1C5uINByFQrnXfRQ8D/d85JgP1ZVK6usjEWk4dQ0FM7vE\nzLab2Q4zu7bC9j82sz4z2xI83l7Peqa18EQ4/93wyL/BM/cd06Ey6ST/vfcAQ6P1melNRKQe6hYK\nZhYHbgbWA2uBt5rZ2gpN/9Xdzw4en69XPVV71Z9B4ni46y8hnz/qw3SlEuQdnnhusIbFiYjUVz3P\nFF4G7HD3J919BLgduLSO71cbLfPhddfBri3wy68e9WFKE+7oKyQRaSD1DIXlwLNlr3uDdRO92cwe\nNrNvmNnKSgcys41mttnMNvf19dWj1vHOvBxWvhzuuQ6Gju4f9RMWzaO9Oa5Z2ESkodQzFKzCuom3\n+H4XWOXuLwHuAb5U6UDufqu7d7t7d2dnZ43LrMCscInqgT3wk08e1SHiGu5CRBpQPUOhFyj/y38F\nsLO8gbvvc/fh4OXngHPrWM+RWb4Ozr4S7vss7PvVUR2iK12YcEfDXYhIo6hnKDwAnGJmq82sBXgL\ncEd5AzNLl718E9BTx3qO3Gs/BE2tRz11ZyaV5IWDo+wZGJ6+sYjILFC3UHD3LPAu4G4K/9h/3d0f\nM7PrzexNQbN3m9ljZvZL4N3AH9ernqOSWAa/8efw+F2w454j3j2TKtzZvFWdzSLSIOp6n4K73+nu\np7r7Gnf/WLDuQ+5+R7D8fnc/3d3PcvcL3X1bPes5Kue9Axauhu994Iin7ixegaR+BRFpFLqjeTpN\nrYWpO/duhwe+cES7HtfezPIF7WzTFUgi0iAUCtU4bT2cdCH8x8fhwL4j2jWjK5BEpIEoFKpRnLpz\neBDu/dgR7ZpJJ/hV3yDDWQ13ISKzn0KhWku74KVvhwdvg92PVr1bJpUkm3d27NFwFyIy+ykUjsSF\n74e2BfC9a6ueurNLnc0i0kAUCkeifSFc9EF46j+h547p2wOrFs+jtSmmzmYRaQgKhSO17o9h6enw\n/b+qaurOpniMU5cl2KYJd0SkASgUjlS8qdDp/OIz8F83VbVLJpWgR18fiUgDUCgcjZMugK7fLkzd\n2b9z2uaZdJK9g8P0abgLEZnlFApH63UfhXyuqqk7u9KF4S7UryAis51C4WgtWg2vfBc8/K/w7P2H\nbZpJ6QokEWkMCoVj8ar3QEdq2qk7F81vYVmyVRPuiMisp1A4Fq0dhak7dz4ED99+2KaZVFKdzSIy\n6ykUjtWZvwvLuwt9C8NT/6OfSSfYsWeA0dzUZxQiImFTKByrWAzW/x0MPgc/+fspm61NJxnNOU/2\nHZjB4kREjoxCoRZWnAtn/R7c909TTt1Z6mxWv4KIzGIKhVq5+MMQb4Hv/3XFzSd1zqc5bupXEJFZ\nTaFQK4kUvPq9sP3/wq9+NGlzczzGyUsT9GhqThGZxRQKtXTen8DCVfC990MuO2lzVyqhr49EZFZT\nKNRScxu8/mPQtw02b5q0uSud5Ln+YZ4/MBJCcSIi01Mo1FrmN2H1BYUZ2g4+P36ThrsQkVlOoVBr\nZnDJDTDcD/d+fNwmDXchIrOdQqEelq2F7qtg8xfgucdKqzsTrSzpaFFns4jMWgqFernwA9B23KSp\nOzOpJI/t7NedzSIyKzWFXcCcNW8RXPhBuPN9sO3fC/MvAKcfn+Sff/Ikp/7VXSye30Jnoo1lyVaW\nJlpZlmxjaaKVpcHzsmQbnYlWmuPKbhGZGQqFejp3AzzwBbj7g3Dy66C5jasvWMOJi+fzXP8QewaG\n2RM8b93Zz97BYfI++TCF8BgLjWXJNpYGQVIMkM5EK61N8Zn/GUVkTlEo1FO8CdbfAF++FO67GV79\nXhbOb+H3Xn5Cxea5vLNvcJg9A8Ol0JgYHtt297N3cIRchfRYOK+5dHYxLkDKwmNpUuEhIlNTKNTb\nSa+BzG/BT/6hMD5SMj1l03jMCv94J9s4Y/lxU7bL5Z19B4bZ01+Y4rNSgOzYM8iegeGK4bFgXjPL\nEm0smNfMvJY481qaaG+JM68lTntzfGy5pYl5wev2ljjzmsfaFl+3t8RpbYphZjX4sEQkbAqFmfD6\nj8LNL4cfXgf/45ZjPlw8ZixNtLE00XbYdvm88/zBkfFnG/3DPDdQeH7x0Ch7B0c4OHKQQyM5Do3m\nODiSYzh7ZJ3gMYN5LU20NceDkIlPCJmxcBkfPE3Ma4nT1hyjtSlOS1OM1qbCcmtzjJZ4jNYJ25pi\npgASqSOFwkxYdBK84p3w03+El74dVnTPyNvGYsaSjlaWdLRy+hHsl8t7EBBZhkbyHBzNcnAkx6GR\nQmgcGs1xaKSw7uBIjqEgTAptsmVtcrxwYLR0rGLwjOYqdJxU+zMZ4wOkGBqlAInR0hQPwiU2uW08\nRmvz2PaWYgg1xWiKx2iKG82x4DluNMViNMdjheV4IZSaJ7QrLsdiCitpfAqFmfLq98KWrxam7rzq\nB4V5GGapeMzoaG2io7U+/3uM5vLjwmRoNMdINs9wNs9wNsfwaJ6R3NjycDYfbM8Fbcpej+ZL64rb\n9x8anbR9pGzfeokZQYAEYRErhklZgMTGB0xLcPbTVAyeWOF1PFbYLx4rrCs8W9lzrGz7hPWT9p+w\nftz2CutjMeJxI26F1+WPppgRs+BZITgnKRRmSmsCLv4IfOcd8MjX4ay3hF1RaJrjMY5rj3Fce/OM\nv7e7M5LLl4VQnuHRQmBkc85ovvCczRWCKZtzsvk8o+XP45bzZPPOaC7PaNB+dIrtk46VdQaHs8E+\nhXbF9rmyR7b0nCeX92M606olM6oKjnHPFoRRhf3isRhxo/Acg6bg7CtmEDPDguex14XlsfVTt4mV\n2o5vY8F+Fd8jNnn/WFndxeWxdWN1VFo/eZ/J68e3KdQQL2szE2Fs7rPjf7BqdXd3++bNm8Mu4+jk\n8/CFi2HnL6B5PjS1QLy1wnPbYba1FuZtaCouT1hXep6wT6VtsWaIxcHiwbP+8msU+QphkS0PkdwU\n64PQq7i++Lq0L+TcyeXy5BxyxXVB21INXni/nI8Ps9LDfVz70rMX3muq/bL5PHkvBHneIe+OB8/5\nYJ1PeD5cm+K2Rnb1BWu4dn3mqPY1swfdfdrvrut6pmBmlwCfBuLA5939hgnbW4EvA+cC+4Ar3P2p\netYUqlgMLv8iPPglGD0EuWHIDkNuBLJDkB0J1o0U5nvO7g22FdsNj7XJ1Wmk1VJAFJ9jhUdxXfly\nLDbFutgRHCc2fvu4RxBUFbfFxoJsqu2H27/0nmXbsbHXUy4zeT02dqyKy1R57PLjFZ+p+D4xjJZJ\nbSc8x6wwZkHFuio9T7Wdqdcf7v0nPpc+u/D++PCy0HAmhkjwOj8+VMYtlwVdPj8WaPkgQPPF9aU2\njLUN1rl7KXArHa+4rvje5dvXnbCw7p9R3ULBzOLAzcDrgF7gATO7w923ljW7CnjB3U82s7cAnwCu\nqFdNs8KCE+C1lWdnOyLuY4FRCpXhCevKgiQ7NHlbfhTyOQq/BcGz54LlXOE9isuldfnCGU9p3YTl\nwx5npPJxPD/5ka+w7kge0gCmCxImLJftN+lQlYJm8jozI4i/aY43xYqJATdlrRXCcNJ2Dt+20n5t\nfwQnv6vCz1o79TxTeBmww92fBDCz24FLgfJQuBT4SLD8DeAmMzNvtO+0wmA29rWQTHbYUAmCalwI\n5QAfW19cLq0rLuenWJ6w31TrD3uMPDiT33tSLRXqKz1zDPtWeQyqbDPuZ6ni55rq+OWq/aehYrsK\n66ppN6n+8uUKtU78LMs/i6raHua4HUsr1Ftb9QyF5cCzZa97gZdP1cbds2a2H1gM7K1jXRIFsRga\n71HkyNXzt6bS+dzEWK6mDWa20cw2m9nmvr6+mhQnIiKT1TMUeoGVZa9XADunamNmTcBxwPMT2uDu\nt7p7t7t3d3Z21qlcERGpZyg8AJxiZqvNrAV4C3DHhDZ3AH8ULF8G/Ej9CSIi4albn0LQR/Au4G4K\nl6RucvfHzOx6YLO73wF8AfjfZraDwhlCdO/oEhGZBep6n4K73wncOWHdh8qWh4DL61mDiIhUT5dn\niIhIiUJBRERKFAoiIlLScAPimVkf8PRR7r4E3RhXTp/HePo8xuizGG8ufB4nuvu01/Q3XCgcCzPb\nXM0ogVGhz2M8fR5j9FmMF6XPQ18fiYhIiUJBRERKohYKt4ZdwCyjz2M8fR5j9FmMF5nPI1J9CiIi\ncnhRO1MQEZHDiEwomNklZrbdzHaY2bVh1xMmM1tpZveaWY+ZPWZm14RdU9jMLG5mvzCzfw+7lrCZ\n2QIz+4aZbQv+H3lF2DWFxcz+LPgdedTMvmZmbWHXVG+RCIWyqUHXA2uBt5rZ2nCrClUWeK+7dwHn\nAe+M+OcBcA3QE3YRs8Snge+5ewY4i4h+Lma2HHg30O3uZ1AY2HPOD9oZiVCgbGpQdx8BilODRpK7\n73L3h4LlAQq/9MvDrSo8ZrYC+E3g82HXEjYzSwK/QWEEY9x9xN1fDLeqUDUB7cF8L/OYPCfMnBOV\nUKg0NWhk/xEsZ2argHOAn4dbSaj+F/AXQD7sQmaBk4A+4Lbg67TPm9n8sIsKg7v/Gvh74BlgF7Df\n3b8fblX1F5VQqGraz6gxsw7gm8Cfunt/2PWEwcx+C9jj7g+GXcss0QSsAz7r7ucAB4BI9sGZ2UIK\n3yisBo4H5pvZleFWVX9RCYVqpgaNFDNrphAIX3H3b4VdT4jOB95kZk9R+FrxIjP7l3BLClUv0Ovu\nxTPHb1AIiSi6GPhvd+9z91HRjE2eAAACg0lEQVTgW8ArQ66p7qISCtVMDRoZZmYUvjPucfdPhV1P\nmNz9/e6+wt1XUfj/4kfuPuf/GpyKu+8GnjWz04JVrwW2hlhSmJ4BzjOzecHvzGuJQKd7XWdemy2m\nmho05LLCdD7wB8AjZrYlWPeBYKY8kf8JfCX4A+pJYEPI9YTC3X9uZt8AHqJwxd4viMCdzbqjWURE\nSqLy9ZGIiFRBoSAiIiUKBRERKVEoiIhIiUJBRERKFAoiATPLmdmWskfN7uQ1s1Vm9mitjidSL5G4\nT0GkSofc/eywixAJk84URKZhZk+Z2SfM7P7gcXKw/kQz+6GZPRw8nxCsX2Zm3zazXwaP4tAIcTP7\nXDA+//fNrD1o/24z2xoc5/aQfkwRQKEgUq59wtdHV5Rt63f3lwE3URhVlWD5y+7+EuArwI3B+huB\nH7v7WRTGDSrePX8KcLO7nw68CLw5WH8tcE5wnKvr9cOJVEN3NIsEzGzQ3TsqrH8KuMjdnwwGEtzt\n7ovNbC+QdvfRYP0ud19iZn3ACncfLjvGKuAH7n5K8PovgWZ3/xsz+x4wCHwH+I67D9b5RxWZks4U\nRKrjUyxP1aaS4bLlHGN9er9JYWbAc4EHgwldREKhUBCpzhVlz/8VLP+MsekZfx/4abD8Q+AdUJr7\nOTnVQc0sBqx093spTPSzAJh0tiIyU/QXiciY9rJRY6EwT3HxstRWM/s5hT+k3hqsezewycz+nMJs\nZcXRRK8BbjWzqyicEbyDwsxdlcSBfzGz4yhMBvWPEZ/+UkKmPgWRaQR9Ct3uvjfsWkTqTV8fiYhI\nic4URESkRGcKIiJSolAQEZEShYKIiJQoFEREpEShICIiJQoFEREp+f9pNrWvfWTOwQAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train: 98.80580357142857% Accuracy Test: 98.14285714285714%\n"
     ]
    }
   ],
   "source": [
    "# -- 誤差の記録をグラフ表示 -- \n",
    "plt.plot(train_error_x, train_error_y, label=\"Train\")\n",
    "plt.plot(test_error_x, test_error_y, label=\"Test\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# -- 正解率の測定 -- \n",
    "x, t = forward_sample(X_train, y_train, n_train) \n",
    "count_train = np.sum(np.argmax(ol_1.y, axis=1) == np.argmax(t, axis=1))\n",
    "\n",
    "x, t = forward_sample(X_test, y_test, n_test) \n",
    "count_test = np.sum(np.argmax(ol_1.y, axis=1) == np.argmax(t, axis=1))\n",
    "\n",
    "print(\"Accuracy Train:\", str(count_train/n_train*100) + \"%\",\n",
    "      \"Accuracy Test:\", str(count_test/n_test*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 畳み込み層とは何か\n",
    "畳み込みは、画像処理の分野ではポピュラーな演算であり、画像に対して畳み込みを行うことで、画像のある特徴を強めたり、弱めたりすることができる。   \n",
    "畳み込み層では、この畳み込み処理により入力画像をより特徴が強調されたものに変換する。    \n",
    "また、画像には局所性という性質がある。局所性とは、各ピクセルが近傍のピクセルと強い関連性を持っている性質のことである。例えば、ある隣り合ったピクセル同士は似たような色になる可能性が高いし、複数のピクセルからなるかたまりが物体の輪郭を構成することもある。畳み込み層は、このような画像の局所性を利用して画像の特徴を検出する。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プーリング層とは何か\n",
    "プーリング層は通常、畳み込み層の直後に配置される。プーリング層では画像を各領域に区切り、各領域を代表する値を抽出し並べて新たな画像とする。このような処理をプーリングという。      \n",
    "プーリングの代表的な方法として、各領域の最大値を各領域の代表とする値とするMAXプーリングが使われることが多い。   \n",
    "プーリングは言わば画像をぼかす処理なので、対象の位置の感度が低下する。これにより、対象の位置が多少変化しても、結果は同じようになる。また、プーリングにより画像サイズが小さくなるので、計算量が削減される効果もある。     \n",
    "プーリング層で区切る領域は固定であり、学習するパラメータがないので学習は行われない。また、チャンネルが合流したり分岐したりすることはないので、入力のチャンネル数と出力のチャンネル数は同じになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNは全結合層のみのニューラルネットワークとどのように違うか\n",
    "ノードからノードに全て結合するのが全結合であり、全てでない手抜きが非全結合である。全結合層のみのニューラルネットワークで計算すると処理が膨大になってしまう。このため、畳み込み層やプーリング層では、非全結合で処理することにより、大幅に計算を削減することができる。    \n",
    "また、全結合層の問題点として、形状を無視して、すべての入力データを同じ次元のニューロンとして扱うので、形状に関する情報を生かすことができない。一方で、折り畳み層は形状を維持するため、CNNでは、画像などの形状を有したデータを正しく理解することができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 出力サイズとパラメータ数の計算\n",
    "1. 出力サイズ　142×142=20,164、パラメータ数　142×142×3×6=362,952      \n",
    "2. 出力サイズ　58×58=3,364、    パラメータ数　58×58×24×48=3,875,328      \n",
    "2. 出力サイズ　10×10=100、    パラメータ数　10×10×10×20=20,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フィルタサイズ\n",
    "#### 7×7などの大きめのものではなく、3×3のフィルタが一般的に使われる理由 \n",
    "例えば、５×５などの大きめのものに比べて、畳み込みの操作を、3×3のフィルタにより連続した畳み込み演算で置き換えることによって、より少ないパラメータ数で実現できる。    \n",
    "また、3×3畳み込みは、２×２畳み込みよりも、パラメータ数が削減されることが分かっており、一般的には3×3のフィルタが使われている。\n",
    "#### 高さや幅方向を持たない1×1のフィルタの効果   \n",
    "1×1のフィルタは、チャンネル方向には画素数を加算するので、非自明な作用をする。また、フィルタのチャネル数を元画像よりも少なくしておくことで、返還後の画像のチャネル数削減が行える。    \n",
    "さらに、サイズの大きなデータの畳み込み演算は計算量がかさむため、中間層で次元削減をすることで計算にかかるコストを下げたい場合に、この1×1畳み込みが利用される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1次元と2次元畳み込みの違い\n",
    "1次元畳み込みは、時系列データ、つまりグラフを用いて、その中にパターンを見つけ、時系列データの特徴を捉える。     \n",
    "一方で、2次元畳み込は、画像の特徴を表すパターンを抽出する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
