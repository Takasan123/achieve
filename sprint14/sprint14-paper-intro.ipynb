{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIF_sprint14-paper-intro\n",
    "### この課題の目的\n",
    "・論文に触れ続ける一歩目を踏み出す   \n",
    "・論文から有益な情報を引き出せるようにする   \n",
    "・これまで扱ってきた領域の論文から新たな知識を得る   \n",
    "【目的としないこと】    \n",
    "・取り上げた論文の内容を完璧に理解する    \n",
    "・論文の書き方を覚える"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 物体検出の分野にはどういった手法が存在したか。\n",
    "物体検出の分野は、アルゴリズムの違いによってR-CNN系、YOLO系、SSD系の大きく３つに分かれる。  \n",
    "R-CNN系では、R-CNN (Region-based CNN)、Fast R-CNN、Faster R-CNNなどがある。\n",
    "\n",
    "引用1：\"Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. \"     \n",
    "\"Recent advances in object detection are driven by the success of region proposal methods ( e.g., [4]) and region-based convolutional neural networks (R-CNNs) [5]. \"     \n",
    "Fast R-CNNについては、出典；Fast R-CNN　Ross Girshick　Microsoft Research　　https://arxiv.org/pdf/1504.08083.pdf　参照"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Fasterとあるが、どういった仕組みで高速化したのか。\n",
    "Fast R-CNN のネットワーク全体のボトルネックは、Selective Search を利用した領域候補の生成部分にある。     \n",
    "Faster R-CNN では、RoI(Region of Interest)の生成のために、Selective Search（物体らしさを見つける既存の手法）を RPN(Region Proposal Network) と言われる小さな畳み込みネットワークに入れ替えた。RPNへ渡す特徴マップの生成前に一度だけCNNを実行することにより、高速化を実現した。    \n",
    "\n",
    "引用：\"Our object detection system, called Faster R-CNN, is composed of two modules. The first module is a deep fully convolutional network that proposes regions, and the second module is the Fast R-CNN detector [2] that uses the proposed regions. \"     \n",
    "\"We therefore need to develop a technique that allows for haring convolutional layers between the two networks, rather than learning two separate net-works. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) One-Stageの手法とTwo-Stageの手法はどう違うのか。\n",
    "物体検出は、第１ステージの物体候補の抽出と第２ステージの物体認識があり、Two-stageで物体検出を行う代表的な手法がR-CNN系である。Two-stageの物体検出は、処理速度を改善したFaster R-CNNでも、まだ処理速度が遅いと言われる。     \n",
    "そこで、第１ステージと第２ステージを一気にやるOne-stageの物体検出手法が誕生し、その代表がYolo系とSSD系である。 \n",
    "\n",
    "引用：\"OverFeat is a one-stage, class-specific detection pipeline, and ours is a two-stage cascade consisting of class-agnostic pro-posals and class-specific detections. In OverFeat, the region-wise features come from a sliding window of one aspect ratio over a scale pyramid. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) RPNとは何か。\n",
    "RPN(Region Proposal Network)は、入力画像中から物体候補領域(物体が存在し得る画像領域の候補)を抽出するためのネットワークである。     \n",
    "RPNは、物体候補を出力するための2つの機能を持っている。\n",
    "1つ目は、枠内の画像が物体かどうかを表すスコアを計算する機能である。    \n",
    "2つ目は、枠の概説矩形のスケールや位置を回帰により微調整する機能である。枠は、あらかじめ定義されたk個の外接矩形(Anchor)を用いて決定される。このAnchor boxにさまざまな形、サイズを用意しておくとで多種多様な物体を検出できるようになる。    \n",
    "\n",
    "引用：\"A Region Proposal Network (RPN) takes an image (of any size) as input and outputs a set of rectangular object proposals, each with an objectness score.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) RoIプーリングとは何か。\n",
    "RoIプーリングは畳み込みニューラルネットワークを使用する物体検出タスクで広く使用される操作である。RoIプーリングの目的は、不均一なサイズの入力に対して最大プールを実行して、固定サイズの特徴マップを得ることである。     \n",
    "2015年4月にRoss Girshickによって最初に提案された。    \n",
    "(page6の3.2 Sharing Features for RPN and Fast R-CNNより）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Anchorのサイズはどうするのが適切か。\n",
    "Anchorはあらかじめ検出したい物体の種類や大きさからいくつかのパターンとするかを決めておく。例えば大きさのパターンを128画素、256画素、512画素の3つ、縦横の比率を、1：2、2：1、1：1の３つにするというように決める。この場合、Anchorは３×３＝９パターンとなる。    \n",
    "\n",
    "引用：\"Even such a large stride provides good results, though accuracy may befurther improved with a smaller stride. For anchors, we use 3 scales with box areas of 128, 256 , and 512 pixels, and 3 aspect ratios of 1:1, 1:2,and 2:1. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7) 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。\n",
    "PASCAL（Pattern Analysis, Statistical Modelling and Computational Learning）が主催するコンペティション VOC 2007,2012のデータセット、および\n",
    "COCO（MicrosoftのCOCO challenge）というデータセットを使っている。     \n",
    "これらのデータセットを使い、先行研究に比べて、Faster R-CNNにおいて、物体の検出精度および検出スピードの向上が得られている。   \n",
    "\n",
    "引用：\"We present more results on the Microsoft COCO object detection dataset [12]. This dataset involves 80 object categories. We experiment with the 80k images on the training set, 40k images on the validation set, and 20k images on the test-dev set. We evaluate the mAP averaged for IoU ∈ [0.5 : 0.05 : 0.95] (COCO’s standard metric, simply denoted as mAP@[.5, .95]) and mAP@0.5 (PASCAL VOC’s metric).\"    \n",
    "\"Using the COCO training set to train, Faster R-CNN has 42.1% mAP@0.5 and 21.5% mAP@[.5, .95] on the COCO test-dev set. This is 2.8% higher for mAP@0.5 and 2.2% higher for mAP@[.5, .95] than the Fast R-CNN counterpart under the same protocol (Table 11).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
