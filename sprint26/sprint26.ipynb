{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GLupXFHSN0eI",
    "outputId": "d4b80b3f-0366-4e89-f0c9-2a1c2a1bf1f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.initializers import orthogonal\n",
    "from keras.initializers import TruncatedNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ERFYZXmM75OI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "g4h58YY6N0eN",
    "outputId": "096548c3-a81a-4951-bb0a-5e9cd57e40c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape= (13292, 1)\n",
      "t_data.shape= (13291, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 学習データ\n",
    "df1 = csv.reader(open('x-data.csv', 'r'))\n",
    "data1 = [ v for v in df1]\n",
    "mat = np.array(data1)\n",
    "mat2 = mat[1:]                        # 見出し行を外す\n",
    "x_data = mat2[:, 1:].astype(float)  # 2列目以降を抜き出してfloat変換\n",
    "print('x_data.shape=', x_data.shape)\n",
    "\n",
    "# ラベルデータ\n",
    "# 1％以上／0％以上／-1％以上／-1％未満\n",
    "df2 = csv.reader(open('t-data.csv', 'r'))\n",
    "data2 = [ v for v in df2]\n",
    "mat3 = np.array(data2)\n",
    "mat4 = mat3[1:]                       # 見出し行を外す\n",
    "t_data = mat4[:, 1:].astype(float)  # 2列目以降を抜き出してfloat変換\n",
    "print('t_data.shape=', t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bWDwZ0lgN0eR"
   },
   "outputs": [],
   "source": [
    "maxlen = 80              # 入力系列数\n",
    "n_in = x_data.shape[1]   # 学習データ（＝入力）の列数\n",
    "n_out = t_data.shape[1]  # ラベルデータ（=出力）の列数\n",
    "len_seq = t_data.shape[0] - maxlen + 1\n",
    "data = []\n",
    "target = []\n",
    "for i in range(0, len_seq):\n",
    "    data.append(x_data[i:i+maxlen, :])\n",
    "    target.append(t_data[i+maxlen-1, :])\n",
    "    \n",
    "    x = np.array(data).reshape(len(data), maxlen, n_in)\n",
    "    t = np.array(target).reshape(len(data), n_out)\n",
    "    \n",
    "    #print(x.shape, t.shape)\n",
    "\n",
    "# ここからソースコードの後半\n",
    "n_train = int(len(data)*0.9)              # 訓練データ長\n",
    "x_train,x_test = np.vsplit(x, [n_train])  # 学習データを訓練用とテスト用に分割\n",
    "t_train,t_test = np.vsplit(t, [n_train])  # ラベルデータを訓練用とテスト用に分割\n",
    "\n",
    "#print(x_train.shape, x_test.shape, t_train.shape, t_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42eUVBUnN0eY"
   },
   "outputs": [],
   "source": [
    "class Prediction :\n",
    "  def __init__(self, maxlen, n_hidden, n_in, n_out):\n",
    "    self.maxlen = maxlen\n",
    "    self.n_hidden = n_hidden\n",
    "    self.n_in = n_in\n",
    "    self.n_out = n_out\n",
    "\n",
    "  def create_model(self):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(self.n_hidden, batch_input_shape = (None, self.maxlen, self.n_in),\n",
    "             kernel_initializer = glorot_uniform(seed=20181228), \n",
    "             recurrent_initializer = orthogonal(gain=1.0, seed=20181228), \n",
    "             dropout = 0.5, \n",
    "             recurrent_dropout = 0.5))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(self.n_out, \n",
    "            kernel_initializer = glorot_uniform(seed=20181228)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer = \"RMSprop\", metrics = ['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "  # 学習\n",
    "  def train(self, x_train, t_train, batch_size, epochs) :\n",
    "    #early_stopping = EarlyStopping(patience=0, verbose=1)\n",
    "    model = self.create_model()\n",
    "    model.fit(x_train, t_train, batch_size = batch_size, epochs = epochs, verbose = 1,\n",
    "          shuffle = True, validation_split = 0.1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2244
    },
    "colab_type": "code",
    "id": "VmUNdOlcN0eb",
    "outputId": "093142cf-b2d2-4c92-f080-a8d7480a6c4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10701 samples, validate on 1189 samples\n",
      "Epoch 1/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2866 - categorical_accuracy: 0.3787 - val_loss: 1.4166 - val_categorical_accuracy: 0.2927\n",
      "Epoch 2/100\n",
      "10701/10701 [==============================] - 54s 5ms/step - loss: 1.2761 - categorical_accuracy: 0.3886 - val_loss: 1.4574 - val_categorical_accuracy: 0.2960\n",
      "Epoch 3/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2709 - categorical_accuracy: 0.3928 - val_loss: 1.4302 - val_categorical_accuracy: 0.3028\n",
      "Epoch 4/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2684 - categorical_accuracy: 0.3919 - val_loss: 1.4127 - val_categorical_accuracy: 0.2918\n",
      "Epoch 5/100\n",
      "10701/10701 [==============================] - 56s 5ms/step - loss: 1.2706 - categorical_accuracy: 0.3922 - val_loss: 1.4702 - val_categorical_accuracy: 0.3019\n",
      "Epoch 6/100\n",
      "10701/10701 [==============================] - 56s 5ms/step - loss: 1.2674 - categorical_accuracy: 0.3908 - val_loss: 1.5085 - val_categorical_accuracy: 0.2918\n",
      "Epoch 7/100\n",
      "10701/10701 [==============================] - 53s 5ms/step - loss: 1.2663 - categorical_accuracy: 0.3959 - val_loss: 1.4646 - val_categorical_accuracy: 0.2977\n",
      "Epoch 8/100\n",
      "10701/10701 [==============================] - 53s 5ms/step - loss: 1.2655 - categorical_accuracy: 0.3927 - val_loss: 1.4916 - val_categorical_accuracy: 0.2969\n",
      "Epoch 9/100\n",
      "10701/10701 [==============================] - 53s 5ms/step - loss: 1.2628 - categorical_accuracy: 0.3906 - val_loss: 1.4553 - val_categorical_accuracy: 0.3019\n",
      "Epoch 10/100\n",
      "10701/10701 [==============================] - 53s 5ms/step - loss: 1.2637 - categorical_accuracy: 0.3890 - val_loss: 1.4635 - val_categorical_accuracy: 0.2952\n",
      "Epoch 11/100\n",
      "10701/10701 [==============================] - 52s 5ms/step - loss: 1.2678 - categorical_accuracy: 0.3863 - val_loss: 1.4760 - val_categorical_accuracy: 0.2977\n",
      "Epoch 12/100\n",
      "10701/10701 [==============================] - 53s 5ms/step - loss: 1.2638 - categorical_accuracy: 0.3882 - val_loss: 1.4843 - val_categorical_accuracy: 0.3003\n",
      "Epoch 13/100\n",
      "10701/10701 [==============================] - 53s 5ms/step - loss: 1.2651 - categorical_accuracy: 0.3864 - val_loss: 1.5188 - val_categorical_accuracy: 0.2893\n",
      "Epoch 14/100\n",
      "10701/10701 [==============================] - 53s 5ms/step - loss: 1.2636 - categorical_accuracy: 0.3804 - val_loss: 1.4986 - val_categorical_accuracy: 0.2918\n",
      "Epoch 15/100\n",
      "10701/10701 [==============================] - 53s 5ms/step - loss: 1.2622 - categorical_accuracy: 0.3906 - val_loss: 1.4538 - val_categorical_accuracy: 0.2986\n",
      "Epoch 16/100\n",
      "10701/10701 [==============================] - 52s 5ms/step - loss: 1.2652 - categorical_accuracy: 0.3850 - val_loss: 1.4871 - val_categorical_accuracy: 0.2969\n",
      "Epoch 17/100\n",
      "10701/10701 [==============================] - 52s 5ms/step - loss: 1.2615 - categorical_accuracy: 0.3873 - val_loss: 1.4529 - val_categorical_accuracy: 0.2994\n",
      "Epoch 18/100\n",
      "10701/10701 [==============================] - 52s 5ms/step - loss: 1.2628 - categorical_accuracy: 0.3831 - val_loss: 1.4990 - val_categorical_accuracy: 0.2935\n",
      "Epoch 19/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2610 - categorical_accuracy: 0.3859 - val_loss: 1.5345 - val_categorical_accuracy: 0.3011\n",
      "Epoch 20/100\n",
      "10701/10701 [==============================] - 56s 5ms/step - loss: 1.2571 - categorical_accuracy: 0.3859 - val_loss: 1.5319 - val_categorical_accuracy: 0.2935\n",
      "Epoch 21/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2624 - categorical_accuracy: 0.3830 - val_loss: 1.4793 - val_categorical_accuracy: 0.2885\n",
      "Epoch 22/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2623 - categorical_accuracy: 0.3810 - val_loss: 1.5054 - val_categorical_accuracy: 0.2944\n",
      "Epoch 23/100\n",
      "10701/10701 [==============================] - 54s 5ms/step - loss: 1.2571 - categorical_accuracy: 0.3916 - val_loss: 1.4736 - val_categorical_accuracy: 0.3011\n",
      "Epoch 24/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2565 - categorical_accuracy: 0.3859 - val_loss: 1.5027 - val_categorical_accuracy: 0.3019\n",
      "Epoch 25/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2564 - categorical_accuracy: 0.3896 - val_loss: 1.4666 - val_categorical_accuracy: 0.2944\n",
      "Epoch 26/100\n",
      "10701/10701 [==============================] - 56s 5ms/step - loss: 1.2581 - categorical_accuracy: 0.3872 - val_loss: 1.4839 - val_categorical_accuracy: 0.2994\n",
      "Epoch 27/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2564 - categorical_accuracy: 0.3872 - val_loss: 1.5125 - val_categorical_accuracy: 0.3003\n",
      "Epoch 28/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2618 - categorical_accuracy: 0.3850 - val_loss: 1.4988 - val_categorical_accuracy: 0.2885\n",
      "Epoch 29/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2553 - categorical_accuracy: 0.3894 - val_loss: 1.4611 - val_categorical_accuracy: 0.3003\n",
      "Epoch 30/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2556 - categorical_accuracy: 0.3812 - val_loss: 1.5103 - val_categorical_accuracy: 0.2784\n",
      "Epoch 31/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2577 - categorical_accuracy: 0.3821 - val_loss: 1.6287 - val_categorical_accuracy: 0.2944\n",
      "Epoch 32/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2600 - categorical_accuracy: 0.3899 - val_loss: 1.4930 - val_categorical_accuracy: 0.2994\n",
      "Epoch 33/100\n",
      "10701/10701 [==============================] - 54s 5ms/step - loss: 1.2576 - categorical_accuracy: 0.3813 - val_loss: 1.4892 - val_categorical_accuracy: 0.2944\n",
      "Epoch 34/100\n",
      "10701/10701 [==============================] - 54s 5ms/step - loss: 1.2615 - categorical_accuracy: 0.3806 - val_loss: 1.5307 - val_categorical_accuracy: 0.2952\n",
      "Epoch 35/100\n",
      "10701/10701 [==============================] - 53s 5ms/step - loss: 1.2599 - categorical_accuracy: 0.3861 - val_loss: 1.4857 - val_categorical_accuracy: 0.3019\n",
      "Epoch 36/100\n",
      "10701/10701 [==============================] - 52s 5ms/step - loss: 1.2615 - categorical_accuracy: 0.3867 - val_loss: 1.4560 - val_categorical_accuracy: 0.2977\n",
      "Epoch 37/100\n",
      "10701/10701 [==============================] - 53s 5ms/step - loss: 1.2598 - categorical_accuracy: 0.3872 - val_loss: 1.5524 - val_categorical_accuracy: 0.2969\n",
      "Epoch 38/100\n",
      "10701/10701 [==============================] - 53s 5ms/step - loss: 1.2601 - categorical_accuracy: 0.3878 - val_loss: 1.4986 - val_categorical_accuracy: 0.2994\n",
      "Epoch 39/100\n",
      "10701/10701 [==============================] - 54s 5ms/step - loss: 1.2649 - categorical_accuracy: 0.3830 - val_loss: 1.5149 - val_categorical_accuracy: 0.2750\n",
      "Epoch 40/100\n",
      "10701/10701 [==============================] - 54s 5ms/step - loss: 1.2581 - categorical_accuracy: 0.3823 - val_loss: 1.4888 - val_categorical_accuracy: 0.3003\n",
      "Epoch 41/100\n",
      "10701/10701 [==============================] - 56s 5ms/step - loss: 1.2581 - categorical_accuracy: 0.3769 - val_loss: 1.5337 - val_categorical_accuracy: 0.2902\n",
      "Epoch 42/100\n",
      "10701/10701 [==============================] - 54s 5ms/step - loss: 1.2549 - categorical_accuracy: 0.3865 - val_loss: 1.5343 - val_categorical_accuracy: 0.2986\n",
      "Epoch 43/100\n",
      "10701/10701 [==============================] - 53s 5ms/step - loss: 1.2579 - categorical_accuracy: 0.3820 - val_loss: 1.4637 - val_categorical_accuracy: 0.2952\n",
      "Epoch 44/100\n",
      "10701/10701 [==============================] - 53s 5ms/step - loss: 1.2607 - categorical_accuracy: 0.3816 - val_loss: 1.4934 - val_categorical_accuracy: 0.2952\n",
      "Epoch 45/100\n",
      "10701/10701 [==============================] - 54s 5ms/step - loss: 1.2546 - categorical_accuracy: 0.3853 - val_loss: 1.5285 - val_categorical_accuracy: 0.2935\n",
      "Epoch 46/100\n",
      "10701/10701 [==============================] - 54s 5ms/step - loss: 1.2599 - categorical_accuracy: 0.3846 - val_loss: 1.4963 - val_categorical_accuracy: 0.3011\n",
      "Epoch 47/100\n",
      "10701/10701 [==============================] - 53s 5ms/step - loss: 1.2629 - categorical_accuracy: 0.3834 - val_loss: 1.5563 - val_categorical_accuracy: 0.2742\n",
      "Epoch 48/100\n",
      "10701/10701 [==============================] - 54s 5ms/step - loss: 1.2637 - categorical_accuracy: 0.3846 - val_loss: 1.5160 - val_categorical_accuracy: 0.2952\n",
      "Epoch 49/100\n",
      "10701/10701 [==============================] - 56s 5ms/step - loss: 1.2581 - categorical_accuracy: 0.3867 - val_loss: 1.5389 - val_categorical_accuracy: 0.2902\n",
      "Epoch 50/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2614 - categorical_accuracy: 0.3854 - val_loss: 1.4412 - val_categorical_accuracy: 0.2935\n",
      "Epoch 51/100\n",
      "10701/10701 [==============================] - 54s 5ms/step - loss: 1.2579 - categorical_accuracy: 0.3806 - val_loss: 1.5034 - val_categorical_accuracy: 0.3011\n",
      "Epoch 52/100\n",
      "10701/10701 [==============================] - 54s 5ms/step - loss: 1.2588 - categorical_accuracy: 0.3886 - val_loss: 1.5559 - val_categorical_accuracy: 0.2935\n",
      "Epoch 53/100\n",
      "10701/10701 [==============================] - 56s 5ms/step - loss: 1.2607 - categorical_accuracy: 0.3871 - val_loss: 1.5675 - val_categorical_accuracy: 0.2910\n",
      "Epoch 54/100\n",
      "10701/10701 [==============================] - 56s 5ms/step - loss: 1.2625 - categorical_accuracy: 0.3857 - val_loss: 1.4484 - val_categorical_accuracy: 0.2935\n",
      "Epoch 55/100\n",
      "10701/10701 [==============================] - 56s 5ms/step - loss: 1.2602 - categorical_accuracy: 0.3824 - val_loss: 1.5060 - val_categorical_accuracy: 0.2952\n",
      "Epoch 56/100\n",
      "10701/10701 [==============================] - 56s 5ms/step - loss: 1.2612 - categorical_accuracy: 0.3804 - val_loss: 1.5657 - val_categorical_accuracy: 0.2767\n",
      "Epoch 57/100\n",
      "10701/10701 [==============================] - 56s 5ms/step - loss: 1.2594 - categorical_accuracy: 0.3840 - val_loss: 1.5164 - val_categorical_accuracy: 0.2910\n",
      "Epoch 58/100\n",
      "10701/10701 [==============================] - 56s 5ms/step - loss: 1.2630 - categorical_accuracy: 0.3890 - val_loss: 1.4947 - val_categorical_accuracy: 0.2902\n",
      "Epoch 59/100\n",
      "10701/10701 [==============================] - 54s 5ms/step - loss: 1.2636 - categorical_accuracy: 0.3900 - val_loss: 1.5489 - val_categorical_accuracy: 0.2935\n",
      "Epoch 60/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2652 - categorical_accuracy: 0.3825 - val_loss: 1.5689 - val_categorical_accuracy: 0.2918\n",
      "Epoch 61/100\n",
      "10701/10701 [==============================] - 54s 5ms/step - loss: 1.2661 - categorical_accuracy: 0.3862 - val_loss: 1.4530 - val_categorical_accuracy: 0.2817\n",
      "Epoch 62/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2614 - categorical_accuracy: 0.3887 - val_loss: 1.5401 - val_categorical_accuracy: 0.2860\n",
      "Epoch 63/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2631 - categorical_accuracy: 0.3868 - val_loss: 1.5598 - val_categorical_accuracy: 0.2977\n",
      "Epoch 64/100\n",
      "10701/10701 [==============================] - 55s 5ms/step - loss: 1.2603 - categorical_accuracy: 0.3813 - val_loss: 1.5149 - val_categorical_accuracy: 0.2927\n",
      "Epoch 65/100\n",
      "  860/10701 [=>............................] - ETA: 50s - loss: 1.2725 - categorical_accuracy: 0.3733Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "n_hidden = 80     # 出力次元\n",
    "epochs = 100      # エポック数\n",
    "batch_size = 10   # ミニバッチサイズ\n",
    "\n",
    "# モデル定義\n",
    "prediction = Prediction(maxlen, n_hidden, n_in, n_out)\n",
    "# 学習\n",
    "model = prediction.train(x_train, t_train, batch_size, epochs)\n",
    "# テスト\n",
    "score = model.evaluate(x_test, t_test, batch_size = batch_size, verbose = 1)\n",
    "print(\"score:\", score)\n",
    "\n",
    "# 正答率、準正答率（騰落）集計\n",
    "preds = model.predict(x_test)\n",
    "correct = 0\n",
    "semi_correct = 0\n",
    "for i in range(len(preds)):\n",
    "    pred = np.argmax(preds[i,:])\n",
    "    tar = np.argmax(t_test[i,:])\n",
    "    \n",
    "    if pred == tar :\n",
    "        correct += 1\n",
    "    else :\n",
    "        if pred+tar == 1 or pred+tar == 5 :\n",
    "            semi_correct += 1\n",
    "\n",
    "print(\"正答率:\", 1.0 * correct / len(preds))\n",
    "print(\"準正答率（騰落）:\", 1.0 * (correct+semi_correct) / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EAbGWf-N9dP6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XQjYsQLTN0ed"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nikkei.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
