{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprint9 NN(ニューラルネットワーク)の実装\n",
    "・スクラッチを通してニューラルネットワークの基礎を理解する     \n",
    "・基本的な深層学習のキーワードを学習する      \n",
    "・画像データの簡単な扱い方を知る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "# 保存先を指定\n",
    "mnist_dir = \"/Users/andoutakaaki/DIC_study/sprint9/mnist_data/\"\n",
    "\n",
    "# MNISTの読み込み\n",
    "mnist = fetch_mldata('MNIST original', data_home=mnist_dir)\n",
    "# trainとtestに分割する\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.14285)\n",
    "# ラベルをint型にしておく\n",
    "y_train = y_train.astype(np.int)\n",
    "y_test = y_test.astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "uint8\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0 134 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254\n",
      " 254 139   9   0   0   0   0   0   0   0   0   0 248 253 253 253 253 253\n",
      " 253 253 253 253 253 253 253 253 253 253 253 253 199   9   0   0   0   0\n",
      "   0   0   0   0  61 235 235 235 235 235 235 235 235 235 174 198 111 214\n",
      " 235 235 242 253 253 138   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  44 243 253 253   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  81 247 253 253   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  64 245 253 253 174\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  17 186 253 253 233  47   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  18 185 253 253 253\n",
      " 112   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  85 205 253 253 253  86   4   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  86 240 253 253 253\n",
      " 197  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  17 102 240 253 253 228 136   6   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  99 253 253 253 228\n",
      "  53   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0 145 240 253 253 227  53   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  15 172 241 253 253 228\n",
      "  53   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  14 121 253 253 253 228  53   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  13 183 253 253 253 198\n",
      "  22   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  23 233 253 253 253 178  51   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  73 238 253 253 253 152\n",
      "   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   3 125 248 253 253 253 154   4   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   4 129 129 129 129  51\n",
      "   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 784)\n",
    "print(X_test.shape) # (10000, 784)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(10000,)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape) \n",
    "print(y_test.shape) \n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練セットの最初の正解がでた"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像データの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJeXwmyX1//L/WSVRJ1sZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAADw5JREFUeJzt3X3MlfV9x/H3R0RdAB0ERWrRPrGs\nm3/QhpA9mA3DNOI/iBtG90dZug1d0dSlM0MU5R+1m7OdbokGAinGB8pWFFM7W2eWiJlPt0+FlrU1\nFhW9xz1CGzExEuS7P+6L9gbvc53DOdd1rnPz/bySO+fhez18c/TDdc75Xdf5KSIws3xOaroBM2uG\nw2+WlMNvlpTDb5aUw2+WlMNvlpTDP8FJ2i3pTzpcNiR9rsv9dL2uDSaH32on6f1j/j6S9C9N95Xd\nyU03YCe+iJh65L6kKcBe4N+a68jAR/4TiqQFkp6V9EtJw5L+VdIpxyx2qaQ3JO2TdKekk8as/2VJ\nuyT9QtL3JZ1XQ5t/BowA22vYth0Hh//E8hHwt8BM4PeBRcBXjllmKTAf+CKwBPgygKTLgNXA5cCZ\njIbz4U52KmmVpO922ONy4P7weeWNk/8bTGySdgN/FRH/OU7teuCPI2Jp8TiAxRHxRPH4K8CfRsQi\nSf8B/HtEbChqJwHvA5+PiDeLdedGxOs99Hou8HPgcxHx8263Y9Xwkf8EIum3JH1X0v9Keg+4ndF3\nAWO9Peb+m8AnivvnAXcXHxl+CewHBJxTYYtfAp5x8AeDw39iuRf4H0aP0Kcz+jZexywzZ8z9c4F3\ni/tvA1dHxG+O+fuNiPjvCvv7ErCpwu1ZDxz+E8s04D3gfUm/DfzNOMvcIGm6pDnAV4FvF8/fB9wo\n6XcBJJ0haVlVjUn6A0bfRfhb/gHh8J9Y/g74c+AAsJ5fB3usbcBLwKvA48AGgIh4BPgHYHPxkWEn\nsLiTnUpaXXxnUGY5sDUiDnSyTaufv/AzS8pHfrOkHH6zpBx+s6QcfrOk+nphT3GWmJnVKCKOPbdj\nXD0d+SVdIuknkl6XtKqXbZlZf3U91CdpEvBT4CJgD/AicFVE/LhkHR/5zWrWjyP/AuD1iHgjIg4C\nmxm9SszMJoBewn8OR18ksodxLgKRtELSkKShHvZlZhXr5Qu/8d5afOxtfUSsA9aB3/abDZJejvx7\nOPoKsU/y6yvEzGzA9RL+F4G5kj5d/FTUlcBj1bRlZnXr+m1/RBySdC3wfWASsDEiflRZZ2ZWq75e\n1efP/Gb168tJPmY2cTn8Zkk5/GZJOfxmSTn8Zkk5/GZJOfxmSTn8Zkk5/GZJOfxmSTn8Zkk5/GZJ\nOfxmSTn8Zkk5/GZJOfxmSTn8Zkk5/GZJOfxmSTn8Zkk5/GZJOfxmSTn8Zkk5/GZJOfxmSTn8Zkk5\n/GZJOfxmSTn8Zkk5/GZJndzLypJ2AweAj4BDETG/iqbMrH49hb9wYUTsq2A7ZtZHfttvllSv4Q/g\nB5JekrRivAUkrZA0JGmox32ZWYUUEd2vLH0iIt6VdBbwJHBdRDxdsnz3OzOzjkSEOlmupyN/RLxb\n3I4AjwALetmemfVP1+GXNEXStCP3gYuBnVU1Zmb16uXb/lnAI5KObOehiHiikq7MrHY9feY/7p35\nM79Z7frymd/MJi6H3ywph98sKYffLCmH3yypKi7smRDuuOOO0vqqVav61IkNgrvuuqu0vmbNmtL6\nBx98UGU7jfCR3ywph98sKYffLCmH3ywph98sKYffLCmH3yypNFf1ffjhh6X1yZMn96kTmwheeOGF\n0vqFF15YWm/yPABf1WdmpRx+s6QcfrOkHH6zpBx+s6QcfrOkHH6zpNKM819wwQWl9UcffbRPnUws\n27dvL62fffbZpfXNmze3rF1zzTWl65555pml9XZOPfXUlrUpU6b0tO12vwdwww039LT9Xnic38xK\nOfxmSTn8Zkk5/GZJOfxmSTn8Zkk5/GZJpRnnt3zOP//8lrVnn322dN1ezwM46aTmjquVjfNL2ihp\nRNLOMc/NkPSkpJ8Vt9N7adbM+q+Tf56+BVxyzHOrgKciYi7wVPHYzCaQtuGPiKeB/cc8vQTYVNzf\nBFxWcV9mVrNu5+qbFRHDABExLOmsVgtKWgGs6HI/ZlaT2ifqjIh1wDrwF35mg6TbryT3SpoNUNyO\nVNeSmfVDt+F/DFhe3F8ObKumHTPrl7Zv+yU9DCwEZkraA9wKfB3YIukvgbeAZXU2adaNuXPntqx5\nnoYOwh8RV7UoLaq4FzPrI5/ea5aUw2+WlMNvlpTDb5aUw2+WVO1n+JnVZeHChaX1Bx98sGXtlFNO\n6Wnf27ZN/FNbfOQ3S8rhN0vK4TdLyuE3S8rhN0vK4TdLyuE3S8rj/Dawpk8v/1Hom266qbR+2mmn\ndb3vffv2ldbXrl3b9bYHhY/8Zkk5/GZJOfxmSTn8Zkk5/GZJOfxmSTn8Zkl5nN8aM2PGjNL65s2b\nS+uLFtX3A9K33357af21116rbd/94iO/WVIOv1lSDr9ZUg6/WVIOv1lSDr9ZUg6/WVIe57daLVvW\nevb2G2+8sXTdefPmVd3Or1x55ZWl9a1bt9a270HR9sgvaaOkEUk7xzy3VtI7kl4t/i6tt00zq1on\nb/u/BVwyzvPfjIh5xd/3qm3LzOrWNvwR8TSwvw+9mFkf9fKF37WSflh8LGj5Y2uSVkgakjTUw77M\nrGLdhv9e4LPAPGAYuKvVghGxLiLmR8T8LvdlZjXoKvwRsTciPoqIw8B6YEG1bZlZ3boKv6TZYx4u\nBXa2WtbMBlPbcX5JDwMLgZmS9gC3AgslzQMC2A1cXWOPNsCuuOKK0vr69etb1qZNm1Z1O0d57rnn\nWtaeeOKJ0nUPHTpUdTsDp234I+KqcZ7eUEMvZtZHPr3XLCmH3ywph98sKYffLCmH3ywpX9KbXLtp\nsMsuyQW48847S+u9DOcNDw+X1h944IHS+po1a1rWDh482FVPJxIf+c2ScvjNknL4zZJy+M2ScvjN\nknL4zZJy+M2S8jh/cpdffnlp/b777qtt3+3G8ZcsWVJaHxryL8P1wkd+s6QcfrOkHH6zpBx+s6Qc\nfrOkHH6zpBx+s6Q8zn+Cu+eee0rry5cvr3X/77zzTsva0qVLS9f1OH69fOQ3S8rhN0vK4TdLyuE3\nS8rhN0vK4TdLyuE3S6qTKbrnAPcDZwOHgXURcbekGcC3gU8xOk33FRHxi/pazeuMM84orW/cuLFl\n7aKLLipdd+rUqV31dES7a/LLxvI9jt+sTo78h4CvRcTngd8DVkr6HWAV8FREzAWeKh6b2QTRNvwR\nMRwRLxf3DwC7gHOAJcCmYrFNwGV1NWlm1Tuuz/ySPgV8AXgemBURwzD6DwRwVtXNmVl9Oj63X9JU\n4DvA9RHxnqRO11sBrOiuPTOrS0dHfkmTGQ3+gxGxtXh6r6TZRX02MDLeuhGxLiLmR8T8Kho2s2q0\nDb9GD/EbgF0R8Y0xpceAI5eELQe2Vd+emdVFEVG+gHQBsB3YwehQH8BqRj/3bwHOBd4ClkXE/jbb\nKt9ZUqeffnppfeXKlaX12267rcp2juKf1554IqKjz+RtP/NHxDNAq40tOp6mzGxw+Aw/s6QcfrOk\nHH6zpBx+s6QcfrOkHH6zpPzT3X0wbdq00vqWLVtK6xdffHGV7Rzl+eefL623G8cfGRn3xE6bAHzk\nN0vK4TdLyuE3S8rhN0vK4TdLyuE3S8rhN0vK4/wVmDVrVml9x44dpfWZM2dW2c5RHn/88dL62rVr\nS+sexz9x+chvlpTDb5aUw2+WlMNvlpTDb5aUw2+WlMNvlpTH+Tu0ePHilrWHHnqodN12U2z3av36\n9S1r1113Xem6Bw8erLodmyB85DdLyuE3S8rhN0vK4TdLyuE3S8rhN0vK4TdLqu04v6Q5wP3A2cBh\nYF1E3C1pLfDXwP8Vi66OiO/V1WivJk2aVFpfvXp1af3mm29uWZs8eXJXPXVqw4YNpfWVK1e2rB06\ndKjqduwE0clJPoeAr0XEy5KmAS9JerKofTMi/qm+9sysLm3DHxHDwHBx/4CkXcA5dTdmZvU6rs/8\nkj4FfAE4MsfTtZJ+KGmjpOkt1lkhaUjSUE+dmlmlOg6/pKnAd4DrI+I94F7gs8A8Rt8Z3DXeehGx\nLiLmR8T8Cvo1s4p0FH5JkxkN/oMRsRUgIvZGxEcRcRhYDyyor00zq1rb8EsSsAHYFRHfGPP87DGL\nLQV2Vt+emdVFEVG+gHQBsB3YwehQH8Bq4CpG3/IHsBu4uvhysGxb5Tur0cknl3+3ecstt/Spk4/b\ntm1baf2VV14prR8+fLi0brlEhDpZrpNv+58BxtvYwI7pm1l7PsPPLCmH3ywph98sKYffLCmH3ywp\nh98sqbbj/JXurMFxfrMsOh3n95HfLCmH3ywph98sKYffLCmH3ywph98sKYffLKl+T9G9D3hzzOOZ\nxXODaFB7G9S+wL11q8rezut0wb6e5POxnUtDg/rbfoPa26D2Be6tW0315rf9Zkk5/GZJNR3+dQ3v\nv8yg9jaofYF761YjvTX6md/MmtP0kd/MGuLwmyXVSPglXSLpJ5Jel7SqiR5akbRb0g5JrzY9v2Ax\nB+KIpJ1jnpsh6UlJPytux50jsaHe1kp6p3jtXpV0aUO9zZH0X5J2SfqRpK8Wzzf62pX01cjr1vfP\n/JImAT8FLgL2AC8CV0XEj/vaSAuSdgPzI6LxE0Ik/RHwPnB/RJxfPPePwP6I+HrxD+f0iPj7Aelt\nLfB+09O2F7NJzR47rTxwGfAXNPjalfR1BQ28bk0c+RcAr0fEGxFxENgMLGmgj4EXEU8D+495egmw\nqbi/idH/efquRW8DISKGI+Ll4v4B4Mi08o2+diV9NaKJ8J8DvD3m8R4afAHGEcAPJL0kaUXTzYxj\n1pFp0Yrbsxru51htp23vp2OmlR+Y166b6e6r1kT4x/t9sUEab/zDiPgisBhYWby9tc50NG17v4wz\nrfxA6Ha6+6o1Ef49wJwxjz8JvNtAH+OKiHeL2xHgEQZv6vG9R2ZILm5HGu7nVwZp2vbxppVnAF67\nQZruvonwvwjMlfRpSacAVwKPNdDHx0iaUnwRg6QpwMUM3tTjjwHLi/vLgfIpfvtoUKZtbzWtPA2/\ndoM23X0jZ/gVQxn/DEwCNkbEbX1vYhySPsPo0R5GL3d+qMneJD0MLGT0ks+9wK3Ao8AW4FzgLWBZ\nRPT9i7cWvS3kOKdtr6m3VtPKP0+Dr12V091X0o9P7zXLyWf4mSXl8Jsl5fCbJeXwmyXl8Jsl5fCb\nJeXwmyX1//L/WSVRJ1sZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35   28.65  148.65  148.65  148.65  148.65\n",
      "   148.65  148.65  148.65  148.65  148.65  148.65  148.65  148.65  148.65\n",
      "   148.65  148.65  148.65   33.65  -96.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35  142.65  147.65  147.65  147.65  147.65\n",
      "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65\n",
      "   147.65  147.65  147.65  147.65   93.65  -96.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35  -44.35  129.65  129.65  129.65  129.65\n",
      "   129.65  129.65  129.65  129.65  129.65   68.65   92.65    5.65  108.65\n",
      "   129.65  129.65  136.65  147.65  147.65   32.65 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35  -61.35  137.65  147.65  147.65 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35  -24.35  141.65  147.65  147.65 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35  -41.35  139.65  147.65  147.65   68.65 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "   -88.35   80.65  147.65  147.65  127.65  -58.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35\n",
      "    79.65  147.65  147.65  147.65    6.65 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -20.35   99.65\n",
      "   147.65  147.65  147.65  -19.35 -101.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -19.35  134.65  147.65\n",
      "   147.65  147.65   91.65  -91.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35  -88.35   -3.35  134.65  147.65  147.65\n",
      "   122.65   30.65  -99.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35   -6.35  147.65  147.65  147.65  122.65\n",
      "   -52.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35   39.65  134.65  147.65  147.65  121.65  -52.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35  -90.35   66.65  135.65  147.65  147.65  122.65  -52.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "   -91.35   15.65  147.65  147.65  147.65  122.65  -52.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -92.35\n",
      "    77.65  147.65  147.65  147.65   92.65  -83.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35  127.65\n",
      "   147.65  147.65  147.65   72.65  -54.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -32.35  132.65  147.65\n",
      "   147.65  147.65   46.65  -99.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -102.35   19.65  142.65  147.65  147.65\n",
      "   147.65   48.65 -101.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -101.35   23.65   23.65   23.65   23.65\n",
      "   -54.35 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "image = image.astype(np.float) # float型に変換\n",
    "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "print(image) # 値を確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理\n",
    "画像は0から255のuint8型で表されたが、機械学習をする上では0から1のfloat型に変更する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解ラベルは0から9の整数であるが、ニューラルネットワークで多クラス分類を行う際にはone-hot表現に変換する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000,)\n",
      "(48000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_one_hot[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重みの初期値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_features = 784\n",
    "# n_node1 = 400\n",
    "# sigma = 0.01  # ガウス分布の標準偏差\n",
    "# W1 = sigma * np.random.randn(n_features, n_node1)\n",
    "# # W1: (784, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# １層目の重み（行７８４、列４００）\n",
    "n_features1 = 784\n",
    "n_node1 = 400\n",
    "sigma = 0.01\n",
    "\n",
    "w1 = sigma*np.random.randn(n_features1, n_node1)\n",
    "b1 = sigma*np.random.randn(n_node1)\n",
    "\n",
    "# ２層目の重み（行４００、列２００）\n",
    "n_features2 = 400\n",
    "n_node2 = 200\n",
    "\n",
    "w2 = sigma*np.random.randn(n_features2, n_node2)\n",
    "b2 = sigma*np.random.randn(n_node2)\n",
    "\n",
    "# 3層目の重み（行２００、列１０）\n",
    "n_features3 = 200\n",
    "n_node3 = 10\n",
    "\n",
    "w3 = sigma*np.random.randn(n_features3, n_node3)\n",
    "b3 = sigma*np.random.randn(n_node3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ミニバッチ処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)または(n_samples,)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "\n",
    "    Retruns\n",
    "    ----------\n",
    "    for文で呼び出すと以下の2つを返す。最後のイテレーションでは、バッチサイズより小さいこともある。\n",
    "    mini_X : 次の形のndarray, shape (batch_size, n_features)\n",
    "      学習データのミニバッチ\n",
    "    mini_y : 次の形のndarray, shape (batch_size, 1)または(batch_size,)\n",
    "      正解値のミニバッチ\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        # ランダムに並べ換える\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._counter = 0\n",
    "        # イテレーション数を計算する\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        # len()が使われたときの処理\n",
    "        return self._stop\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        # for文で呼ばれた際のループごとの処理\n",
    "        if self._counter >= self._stop:\n",
    "            # 最後まで進んだら終了\n",
    "            self._counter = 0 # カウンターをリセット\n",
    "            raise StopIteration()\n",
    "\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このクラスをニューラルネットワークのクラス内でインスタンス化し、for文を使うことでミニバッチが取り出せる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n"
     ]
    }
   ],
   "source": [
    "# 以下をニューラルネットワークのクラス内で呼び出す\n",
    "\n",
    "get_mini_batch = GetMiniBatch(X_train, y_train_one_hot, batch_size=10)\n",
    "\n",
    "print(len(get_mini_batch)) # 4800\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    # このfor文内でミニバッチが使える\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 活性化関数の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 活性化関数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T\n",
    "\n",
    "    x = x - np.max(x)\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "def cross_entropy_error(y_pred, y_train):\n",
    "    if y_pred.ndim == 1:\n",
    "        y_train = y_train.reshape(1, y_train.size)\n",
    "        y_pred = y_pred.reshape(1, y_pred.size)\n",
    "    \n",
    "    batch_size = y_pred.shape[0]\n",
    "    return -np.sum(y_train * np.log(y_pred)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習（フォワード、バックプロパゲーション）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "for i in range(epoch):\n",
    "    get_mini_batch = GetMiniBatch(X_train, y_train_one_hot, batch_size=10, seed=0)\n",
    "\n",
    "    loss_list = []\n",
    "    c = 0\n",
    "    for mini_X_train, mini_y_train in get_mini_batch:\n",
    "        # 1層目\n",
    "        rayer1_pre = np.dot(mini_X_train, w1) + b1\n",
    "        rayer1_out = sigmoid(rayer1_pre)\n",
    "\n",
    "        # 2層目\n",
    "        rayer2_pre = np.dot(rayer1_out, w2) + b2\n",
    "        rayer2_out = sigmoid(rayer2_pre)\n",
    "\n",
    "        # 3層目\n",
    "        rayer3_pre = np.dot(rayer2_out, w3) + b3\n",
    "        rayer3_out = softmax(rayer3_pre)\n",
    "        # print(rayer3_out.shape)\n",
    "\n",
    "        # 損失関数で誤差を算出する\n",
    "        loss = cross_entropy_error(rayer3_out, mini_y_train)\n",
    "        # print(loss)\n",
    "        c = c+1\n",
    "\n",
    "        # def backprob(mini_X_train, mini_y_train, rayer3_out , w1, w2,w3,b1, b2, b3):\n",
    "        delta1 = rayer3_out - mini_y_train\n",
    "        delta2 = (1 - np.tanh(rayer2_pre)**2)*(delta1.dot(w3.T))\n",
    "        delta3 = (1 - np.tanh(rayer1_pre)**2)*(delta2.dot(w2.T))\n",
    "\n",
    "        b3_grad = delta1\n",
    "        w3_grad = rayer2_out.T.dot(delta1) \n",
    "\n",
    "        b2_grad = delta2\n",
    "        w2_grad = rayer1_out.T.dot(delta2) \n",
    "\n",
    "        b1_grad = delta3\n",
    "        w1_grad = mini_X_train.T.dot(delta3) \n",
    "            # return delta2, delta3   \n",
    "\n",
    "        alpha = 0.001\n",
    "        w1= w1 - alpha*w1_grad\n",
    "        w2= w2 - alpha*w2_grad\n",
    "        w3= w3 - alpha*w3_grad\n",
    "        b1 = b1 - alpha*b1_grad.sum(axis=0)\n",
    "        b2 = b2 - alpha*b2_grad.sum(axis=0)\n",
    "        b3 = b3 - alpha*b3_grad.sum(axis=0)\n",
    "\n",
    "\n",
    "        loss_list.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習曲線のプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = list(range(3))\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b1_grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# クロスエントロピー誤差\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mini_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rayer3_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://deepage.net/features/numpy-numpy.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バックプロパゲーション_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # def backprob(mini_X_train, mini_y_train, rayer3_out , w1, w2,w3,b1, b2, b3):\n",
    "# delta1 = rayer3_out - mini_y_train\n",
    "# delta2 = (1 - np.tanh(rayer2_pre)**2)*(delta1.dot(w3.T))\n",
    "# delta3 = (1 - np.tanh(rayer1_pre)**2)*(delta2.dot(w2.T))\n",
    "\n",
    "# b3_grad = delta1\n",
    "# w3_grad = rayer2_out.T.dot(delta1) \n",
    "\n",
    "# b2_grad = delta2\n",
    "# w2_grad = rayer1_out.T.dot(delta2) \n",
    "\n",
    "# b1_grad = delta3\n",
    "# w1_grad = mini_X_train.T.dot(delta3) \n",
    "#     # return delta2, delta3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delta1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b1_grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b1_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w1_grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def gradient_descent_minibatch(X,y,alpha,epoch,lam,batch_size):\n",
    "#     cost=[]\n",
    "#     thetas=[]\n",
    "#     np.random.seed(0)\n",
    "#     w1=np.random.rand()\n",
    "#     w2=np.random.rand()\n",
    "#     b1=np.random.rand()\n",
    "#     b2=np.random.rand()\n",
    "#     epoch = 1\n",
    "#     for i in range(epoch):\n",
    "         \n",
    "#             # Xからランダムにbatch_size分とりだす\n",
    "#         train_size = X.shape[0]\n",
    "#         for mini_X_train,mini_y_train in batch_size:\n",
    "# #             a2=forward(x_batch, w1, w2, b1, b2)\n",
    "# #             costs.append(cross_entropy_error(a2, y_batch, w1, w2, lam))\n",
    "# #             delta2, delta3=backprob(x_batch, y_batch, w1, w2, b1, b2)\n",
    "\n",
    "#             w1= w1 - alpha*w1_grad\n",
    "#             w2= w2 - alpha*w2_grad\n",
    "#             w3= w3 - alpha*w3_grad\n",
    "#             b1 = b1 - alpha*b1_grad.sum(axis=0)\n",
    "#             b2 = b2 - alpha*b2_grad.sum(axis=0)\n",
    "#             b3 = b3 - alpha*b3_grad.sum(axis=0)\n",
    "\n",
    "#     return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradient_descent_minibatch(X,y,alpha,epoch,lam,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネットワークの仕組み\n",
    "多くの層を持つニューラルネットワークを用いた学習を、ディープラーニングという。ディープラーニングは、ヒトの脳に部分的に迫る高度な学習を行うことができるのが特徴。複数の層からなるネットワークに入力と出力があるが、このようなネットワークの各パラメータを最適化することでネットワーク自体が学習する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バックプロパゲーションとは何か\n",
    "バックプロパゲーションとは、ニューラルネットワークを学習させる際に用いられるアルゴリズムで、出力と正解の誤差がネットワークを逆伝搬することにより、ネットワークの重みとバイアスを最適化する。     \n",
    "バックプロパゲーションの手順としては、順伝搬により得られた出力と、あらかじめ用意された正解の誤差を、層を1つずつ遡るように逆伝搬させる。その際に、伝搬した誤差をもとに各層で重みとバイアスの更新量を求める。そして、すべての各層の重みとバイアスを少しずつ更新する。これを繰り返すことで、次第にネットワークは誤差が最小になるように最適化されていき、学習が進行する。学習が成功したネットワークは、任意の入力に対して柔軟に認識・判断ができるようになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 活性化関数の役割とは何か\n",
    "活性化関数とは、言わばニューロンを興奮させるための関数である。ニューロンへの入力と重みを掛けたものの総和にバイアスを足し合わせて統合された値を、ニューロンの興奮状態を表す信号に変換する。活性化関数がないとニューロンの演算は単なる積の総和になってしまい、ニューラルネットワークから複雑な表現をする力が失われる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネットワーク分類器のクラスを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class ScratchSimpleNeuralNetrowkClassifier():\n",
    "#     \"\"\"\n",
    "#     シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "\n",
    "#     Attributes\n",
    "#     ----------\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, verbose = True):\n",
    "#         self.verbose = verbose\n",
    "#         pass\n",
    "#     def fit(self, X, y, X_val=None, y_val=None):\n",
    "#         \"\"\"\n",
    "#         ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             学習用データの特徴量\n",
    "#         y : 次の形のndarray, shape (n_samples, )\n",
    "#             学習用データの正解値\n",
    "#         X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             検証用データの特徴量\n",
    "#         y_val : 次の形のndarray, shape (n_samples, )\n",
    "#             検証用データの正解値\n",
    "#         \"\"\"\n",
    "\n",
    "#         if self.verbose:\n",
    "#             #verboseをTrueにした際は学習過程などを出力する\n",
    "#             print()\n",
    "#         pass\n",
    "\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         \"\"\"\n",
    "#         ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             サンプル\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#             次の形のndarray, shape (n_samples, 1)\n",
    "#             推定結果\n",
    "#         \"\"\"\n",
    "\n",
    "#         pass\n",
    "#         return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # import sys, os\n",
    "# # import pickle\n",
    "# # sys.path.append(os.pardir)\n",
    "\n",
    "# # 活性化関数\n",
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# def softmax(x):\n",
    "#     x = x - np.max(x)\n",
    "#     return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "# def cross_entropy(y, t):\n",
    "#     return (-1) * np.sum(t * np.log(y))\n",
    "\n",
    "# # 1層のみの計算\n",
    "# def eval(X_train, W, B, h):\n",
    "#     A = np.dot(X_train, W1) + B\n",
    "#     Z = h(A)\n",
    "#     return Z\n",
    "\n",
    "# for i in range(len(X_train)):\n",
    "#         h = eval(X_train[i], sigmoid, softmax)\n",
    "#         p = np.argmax(y)\n",
    "#         if p == y[i]:\n",
    "#             ok_cnt += 1\n",
    "# #     print(\"data_num:\" + str(len(x)))\n",
    "# #     print(\"ok_count:\" + str(ok_cnt))\n",
    "# #     print(\"Accuracy:\" + str(float(ok_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def softmax(x):\n",
    "#     if x.ndim == 2:\n",
    "#         x = x.T\n",
    "#         x = x - np.max(x, axis=0)\n",
    "#         y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "#         return y.T\n",
    "\n",
    "#     x = x - np.max(x)\n",
    "#     return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "# np.sum(softmax(X),axis=1) #チェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import sys, os\n",
    "# import pickle\n",
    "# sys.path.append(os.pardir)\n",
    "\n",
    "# # 活性化関数\n",
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# def softmax(x):\n",
    "#     c = np.max(x)\n",
    "#     top = np.exp(x - c)\n",
    "#     bottom = np.sum(np.exp(x - c))\n",
    "#     return top / bottom\n",
    "\n",
    "# # 3層の順方向伝播\n",
    "# def eval_3_network(X, network, h, o):\n",
    "#     W1, W2, W3 \n",
    "#     b1, b2, b3 \n",
    "#     Z1 = eval_single_network(X, W1, B1, h)\n",
    "#     Z2 = eval_single_network(Z1, W2, B2, h)\n",
    "#     Z3 = eval_single_network(Z2, W3, B3, o)\n",
    "#     return Z3\n",
    "\n",
    "# # 1層のみの計算\n",
    "# def eval(X, W, B, h):\n",
    "#     A = np.dot(X, W1) + B\n",
    "#     Z = h(A)\n",
    "#     return Z\n",
    "\n",
    "# # 学習済み重みを読み込む\n",
    "# def load_trained_network():\n",
    "#     with open('sample_weight.pkl', 'rb') as f:\n",
    "#         network = pickle.load(f)\n",
    "#     return network\n",
    "\n",
    "# # テストデータを読み込む\n",
    "# def load_test_data():\n",
    "#     (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "#     return x_test, t_test\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     network = load_trained_network()\n",
    "#     x, t = load_test_data()\n",
    "#     ok_cnt = 0\n",
    "#     for i in range(len(x)):\n",
    "#         y = eval_3_network(x[i], network, sigmoid, softmax)\n",
    "#         p = np.argmax(y)\n",
    "#         if p == t[i]:\n",
    "#             ok_cnt += 1\n",
    "#     print(\"data_num:\" + str(len(x)))\n",
    "#     print(\"ok_count:\" + str(ok_cnt))\n",
    "#     print(\"Accuracy:\" + str(float(ok_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A1 = np.dot(X_train, W1) + B1\n",
    "\n",
    "# Z1 = sigmoid(A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 活性化関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # シグモイド関数の実装\n",
    "# def sigmoid(X):\n",
    "#     return 1 / (1 + np.exp(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # ソフトマックス関数の実装\n",
    "# def softmax(a):\n",
    "#     exp_a = np.exp(a)\n",
    "#     sum_exp_a = np.sum(exp_a)\n",
    "#     y = exp_a / sum_exp_a\n",
    "    \n",
    "#     return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 交差エントロピー誤差の実装\n",
    "# def cross_entropy_error(y, t):\n",
    "#     if y.ndim == 1:\n",
    "#         t = t.reshape(1, t.size)\n",
    "#         y = y.reshape(1, y.size)\n",
    "        \n",
    "#     batch_size = 10\n",
    "#     return -np.sum(t * np.log(y + le-7)) / batch.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （オプション）誤分類の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# 語分類結果を並べて表示する。画像の上の表示は「推定結果/正解」である。\n",
    "\n",
    "# Parameters:\n",
    "# ----------\n",
    "# y_pred : 推定値のndarray (n_samples,)\n",
    "# y_val : 検証用データの正解ラベル(n_samples,)\n",
    "# X_val : 検証用データの特徴量（n_samples, n_features)\n",
    "# \"\"\"\n",
    "\n",
    "# num = 36 # いくつ表示するか\n",
    "\n",
    "# true_false = y_pred==y_val\n",
    "# false_list = np.where(true_false==False)[0].astype(np.int)\n",
    "\n",
    "# if false_list.shape[0] < num:\n",
    "#     num = false_list.shape[0]\n",
    "# fig = plt.figure(figsize=(6, 6))\n",
    "# fig.subplots_adjust(left=0, right=0.8,  bottom=0, top=0.8, hspace=1, wspace=0.5)\n",
    "# for i in range(num):\n",
    "#     ax = fig.add_subplot(6, 6, i + 1, xticks=[], yticks=[])\n",
    "#     ax.set_title(\"{} / {}\".format(y_pred[false_list[i]],y_val[false_list[i]]))\n",
    "#     ax.imshow(X_val.reshape(-1,28,28)[false_list[i]], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
