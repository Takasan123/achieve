{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rL5Ov4QomQYG"
   },
   "source": [
    "## sprint23課題 ゲート付きリカレントニューラルネットワーク\n",
    "1.この課題の目的  \n",
    "広く手法全般を学ぶ経験をする   \n",
    "発展的なRNNの手法を理解する   \n",
    "\n",
    "【目的としないこと】   \n",
    "LSTMやGRUの細かい部分の理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQ5XvcdimQYV"
   },
   "source": [
    "### 説明課題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqH4GBvemQYX"
   },
   "source": [
    "### LSTMやGRUにはゲートと呼ばれるものがあるがこれにはどのような働きがあるか\n",
    "・シンプルRNNは、時系列データの長期の依存関係を学習することが苦手であるが、その理由は、誤差逆伝播時において、tanhノードを通るたびにその値がどんどん小さくなる原因によって、長い系列データを扱う場合は深い層となり、勾配消失が起きるためである。LSTMやGRUにあるゲート付きRNNは、勾配消失に有効な手法であり、時系列データの長期的な依存関係を学習することができるようになる。   \n",
    "・ゲートはデータの流れをコントロールするもので、ゲートには専用の重みがあり、sigmoid関数を使って０.０から1.0までの実数を出力する。LSTMには、inputゲート、forgetゲート、outputゲートの３つのゲート、GRUには、resetゲート、updateゲートの2つのゲートがある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HICy8QcwmQYZ"
   },
   "source": [
    "### SimpleRNN、LSTM、GRUはどのように使い分ければ良いか\n",
    "勾配消失問題によって、一般的にはSimpleRNNは、10時刻(10単語）程度のデータが限界となることが多い。そのため、比較的短いデータに関しての場合のみ、SimpleRNNを使うことが有効である。LSTMは複雑な構造であるが、GRUはLSTMに比べてシンプルな構造となっており、パラメータが少なく、計算時間を短縮している。したがって、GRUはデータセットのサイズが小さい場合や、モデル設計で繰り返しの試行が必要な場合、特に適していると考えられる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N85vAKL_mQYc"
   },
   "source": [
    "### StackedRNNを使うことはどういった効果があるか\n",
    "StackedRNN を使用すると 、RNNレイヤーを時間方向（横方向）ではなく、縦に深く重ねる(層を深く)できる。層を深くすることで表現力の高いモデルを作る事ができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V_0RPpfxmQYm"
   },
   "source": [
    "### ConvLSTMはどういった場面で使われるか\n",
    "通常のLSTMはlinearな状態で処理されるので、画像などは位置的な情報が死んでしまう。convLSTMは画像の状態を維持したまま入力するので位置情報が保持される。linearの場合の行列演算はconvolutionに置き換えれられる。これによりLSTMの時間情報、convolutionの位置情報が同時にいかされる。convLSTMは画像が系列データとして入力されていくので、動画処理などに使われると見られる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mM93xNTXIfMB"
   },
   "source": [
    "## 複数のRecurrentレイヤーを実行（データセット：ロイター）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "zIar1FnpmQYp"
   },
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "YIxR3LuPmQYr",
    "outputId": "e6e103b6-ab3e-460c-a9cb-e84802b48ca7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 0s 0us/step\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (8982, 80)\n",
      "x_test shape: (2246, 80)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 21s 2ms/step - loss: 2.5638 - acc: 0.3518 - val_loss: 2.3148 - val_acc: 0.3673\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 20s 2ms/step - loss: 2.2129 - acc: 0.3545 - val_loss: 2.3113 - val_acc: 0.3629\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 20s 2ms/step - loss: 2.0824 - acc: 0.3530 - val_loss: 2.3660 - val_acc: 0.3602\n",
      "2246/2246 [==============================] - 1s 385us/step\n",
      "Test score: 2.366030941451116\n",
      "Test accuracy: 0.36019590388210565\n"
     ]
    }
   ],
   "source": [
    "# First, let's define a RNN Cell, as a layer subclass.\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "class MinimalRNNCell(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        super(MinimalRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='kernel')\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=(self.units, self.units),\n",
    "            initializer='uniform',\n",
    "            name='recurrent_kernel')\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        prev_output = states[0]\n",
    "        h = K.dot(inputs, self.kernel)\n",
    "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
    "        return output, [output]\n",
    "\n",
    "# Let's use this cell in a RNN layer:\n",
    "\n",
    "# cell = MinimalRNNCell(32)\n",
    "# x = keras.Input((None, 5))\n",
    "# layer = RNN(cell)\n",
    "# y = layer(x)\n",
    "\n",
    "# Here's how to use the cell to build a stacked RNN:\n",
    "\n",
    "cells = [MinimalRNNCell(32), MinimalRNNCell(64)]\n",
    "#x = keras.Input((None, 5))\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RNN\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import GRU\n",
    "from keras.layers import SimpleRNNCell\n",
    "from keras.layers import GRUCell\n",
    "from keras.layers import CuDNNGRU\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.layers import StackedRNNCells\n",
    "from keras.layers import LSTMCell\n",
    "from keras.layers import GRUCell\n",
    "from keras.layers import RNN\n",
    "from keras.datasets import imdb\n",
    "from keras.datasets import reuters\n",
    "from keras.utils import np_utils\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "#(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_features)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(RNN(cells))\n",
    "model.add(Dense(46, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-vELtOi2IfMS"
   },
   "source": [
    "### SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "QPgx-UMsmQY0",
    "outputId": "2134fa01-f365-457a-b492-dd2aef901693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (8982, 80)\n",
      "x_test shape: (2246, 80)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 23s 3ms/step - loss: 2.6476 - acc: 0.3251 - val_loss: 2.4571 - val_acc: 0.3620\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 23s 3ms/step - loss: 2.4325 - acc: 0.3517 - val_loss: 2.4306 - val_acc: 0.3620\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 23s 3ms/step - loss: 2.4303 - acc: 0.3517 - val_loss: 2.4389 - val_acc: 0.3620\n",
      "2246/2246 [==============================] - 1s 481us/step\n",
      "Test score: 2.4389428232571744\n",
      "Test accuracy: 0.36197684778237277\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RNN\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import GRU\n",
    "from keras.layers import SimpleRNNCell\n",
    "from keras.layers import GRUCell\n",
    "from keras.layers import CuDNNGRU\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.layers import StackedRNNCells\n",
    "from keras.layers import LSTMCell\n",
    "from keras.layers import GRUCell\n",
    "from keras.datasets import imdb\n",
    "from keras.datasets import reuters\n",
    "from keras.utils import np_utils\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "#(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_features)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(46, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kfs30eriIfMh"
   },
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Egf4KNkUmQZu",
    "outputId": "c0a133c2-9219-4d31-b3a7-9cfc785ce141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (8982, 80)\n",
      "x_test shape: (2246, 80)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 43s 5ms/step - loss: 2.5616 - acc: 0.3499 - val_loss: 2.4514 - val_acc: 0.3620\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 41s 5ms/step - loss: 2.3433 - acc: 0.3544 - val_loss: 2.0543 - val_acc: 0.4016\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 41s 5ms/step - loss: 1.6740 - acc: 0.5567 - val_loss: 1.4967 - val_acc: 0.6220\n",
      "2246/2246 [==============================] - 2s 878us/step\n",
      "Test score: 1.496661943616553\n",
      "Test accuracy: 0.6219946572213755\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RNN\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.datasets import reuters\n",
    "from keras.utils import np_utils\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "#(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_features)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(46, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "faxywEnYIfMu"
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "EonjranHmQZz",
    "outputId": "9c1b6461-4806-44ec-ffda-b7836c6f667f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (8982, 80)\n",
      "x_test shape: (2246, 80)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 52s 6ms/step - loss: 2.5553 - acc: 0.3489 - val_loss: 2.4511 - val_acc: 0.3620\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 50s 6ms/step - loss: 2.4251 - acc: 0.3517 - val_loss: 2.4357 - val_acc: 0.3620\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 50s 6ms/step - loss: 2.4220 - acc: 0.3517 - val_loss: 2.4281 - val_acc: 0.3620\n",
      "2246/2246 [==============================] - 2s 1ms/step\n",
      "Test score: 2.428080730956257\n",
      "Test accuracy: 0.36197684778237277\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras.datasets import reuters\n",
    "from keras.utils import np_utils\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "# (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_features)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(46, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1-gJVIniIfM2"
   },
   "source": [
    "### SimpleRNNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "xw1hnyHtmQau",
    "outputId": "44e8bade-2745-4330-b039-d2170a77d69d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (8982, 80)\n",
      "x_test shape: (2246, 80)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 24s 3ms/step - loss: 2.6472 - acc: 0.3241 - val_loss: 2.4574 - val_acc: 0.3620\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 22s 3ms/step - loss: 2.4328 - acc: 0.3517 - val_loss: 2.4310 - val_acc: 0.3620\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 23s 3ms/step - loss: 2.4303 - acc: 0.3517 - val_loss: 2.4390 - val_acc: 0.3620\n",
      "2246/2246 [==============================] - 1s 487us/step\n",
      "Test score: 2.439013553323856\n",
      "Test accuracy: 0.36197684778237277\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RNN\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import GRU\n",
    "from keras.layers import SimpleRNNCell\n",
    "from keras.datasets import imdb\n",
    "from keras.datasets import reuters\n",
    "from keras.utils import np_utils\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_features)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(RNN(SimpleRNNCell(128, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(46, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lMm6BKPSIfND"
   },
   "source": [
    "### GRUCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "on5VdyfwmQaz",
    "outputId": "aa44d98f-7735-4e68-976c-1370b5857e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (8982, 80)\n",
      "x_test shape: (2246, 80)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 45s 5ms/step - loss: 2.5616 - acc: 0.3499 - val_loss: 2.4514 - val_acc: 0.3620\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 43s 5ms/step - loss: 2.3433 - acc: 0.3544 - val_loss: 2.0543 - val_acc: 0.4016\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 42s 5ms/step - loss: 1.6740 - acc: 0.5567 - val_loss: 1.4967 - val_acc: 0.6220\n",
      "2246/2246 [==============================] - 2s 875us/step\n",
      "Test score: 1.496661943616553\n",
      "Test accuracy: 0.6219946572213755\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import GRU\n",
    "from keras.layers import GRUCell\n",
    "from keras.datasets import imdb\n",
    "from keras.datasets import reuters\n",
    "from keras.utils import np_utils\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_features)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(RNN(GRUCell(128, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(46, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_OQ_pAYfIfNP"
   },
   "source": [
    "### LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "jpUsRUpjmQbE",
    "outputId": "d87ab8ba-e780-4d2a-e823-0c20480ed2ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (8982, 80)\n",
      "x_test shape: (2246, 80)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 54s 6ms/step - loss: 2.5553 - acc: 0.3489 - val_loss: 2.4511 - val_acc: 0.3620\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 51s 6ms/step - loss: 2.4251 - acc: 0.3517 - val_loss: 2.4357 - val_acc: 0.3620\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 52s 6ms/step - loss: 2.4220 - acc: 0.3517 - val_loss: 2.4281 - val_acc: 0.3620\n",
      "2246/2246 [==============================] - 2s 1ms/step\n",
      "Test score: 2.428080730956257\n",
      "Test accuracy: 0.36197684778237277\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import RNN\n",
    "from keras.layers import LSTMCell\n",
    "from keras.datasets import imdb\n",
    "from keras.datasets import reuters\n",
    "from keras.utils import np_utils\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_features)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(RNN(LSTMCell(128, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(46, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qg2_V03hIfNd"
   },
   "source": [
    "### StackedRNNCells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "alui0bF2xQeS",
    "outputId": "f3499626-afaf-4358-aa7a-885226708d2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (8982, 80)\n",
      "x_test shape: (2246, 80)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 93s 10ms/step - loss: 2.5418 - acc: 0.3506 - val_loss: 2.4309 - val_acc: 0.3620\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 90s 10ms/step - loss: 2.4228 - acc: 0.3517 - val_loss: 2.4350 - val_acc: 0.3620\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 91s 10ms/step - loss: 2.4225 - acc: 0.3517 - val_loss: 2.4304 - val_acc: 0.3620\n",
      "2246/2246 [==============================] - 4s 2ms/step\n",
      "Test score: 2.4304483403930255\n",
      "Test accuracy: 0.36197684778237277\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import LSTMCell\n",
    "from keras.layers import RNN\n",
    "from keras.layers import StackedRNNCells\n",
    "from keras.datasets import imdb\n",
    "from keras.datasets import reuters\n",
    "from keras.utils import np_utils\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_features)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "cells = [LSTMCell(128, dropout=0.2, recurrent_dropout=0.2),LSTMCell(128, dropout=0.3, recurrent_dropout=0.3)]\n",
    "model.add(RNN(StackedRNNCells(cells)))\n",
    "model.add(Dense(46, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L20WRGsBIfNw"
   },
   "source": [
    "### CuDNNGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "vIuVtxPtIfNw",
    "outputId": "3fb67e8d-ff14-47f8-a709-d559f467cf3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 1s 1us/step\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (8982, 80)\n",
      "x_test shape: (2246, 80)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 8s 929us/step - loss: 2.5501 - acc: 0.2161 - val_loss: 2.4057 - val_acc: 0.2110\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 6s 699us/step - loss: 2.1100 - acc: 0.3378 - val_loss: 1.9679 - val_acc: 0.4123\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 6s 694us/step - loss: 1.7589 - acc: 0.4611 - val_loss: 1.5761 - val_acc: 0.5939\n",
      "2246/2246 [==============================] - 0s 199us/step\n",
      "Test score: 1.5760941053222357\n",
      "Test accuracy: 0.5939447907656299\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RNN\n",
    "from keras.layers import CuDNNGRU\n",
    "from keras.datasets import imdb\n",
    "from keras.datasets import reuters\n",
    "from keras.utils import np_utils\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "#(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_features)\n",
    "# 他クラス分類対応\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "# 他クラス分類対応\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(CuDNNGRU(128))\n",
    "model.add(Dense(46, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CjTik0LfIfN2"
   },
   "source": [
    "### CuDNNLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "W3nUMCWkIfN7",
    "outputId": "96372874-18a3-407d-ccfd-8c1e6265a85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (8982, 80)\n",
      "x_test shape: (2246, 80)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 7s 755us/step - loss: 2.5519 - acc: 0.3515 - val_loss: 2.4473 - val_acc: 0.3620\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 6s 678us/step - loss: 2.4303 - acc: 0.3517 - val_loss: 2.4327 - val_acc: 0.3620\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 6s 680us/step - loss: 2.4232 - acc: 0.3517 - val_loss: 2.4263 - val_acc: 0.3620\n",
      "2246/2246 [==============================] - 0s 192us/step\n",
      "Test score: 2.426268374399744\n",
      "Test accuracy: 0.36197684778237277\n"
     ]
    }
   ],
   "source": [
    "# 他クラス分類対応\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RNN\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import GRU\n",
    "from keras.layers import SimpleRNNCell\n",
    "from keras.layers import GRUCell\n",
    "from keras.layers import CuDNNGRU\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.datasets import imdb\n",
    "from keras.datasets import reuters\n",
    "from keras.utils import np_utils\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "#(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_features)\n",
    "# 他クラス分類対応\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "# 他クラス分類対応\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(CuDNNLSTM(128))\n",
    "# 他クラス分類対応\n",
    "model.add(Dense(46, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "# 他クラス分類対応\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "#model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LLLRFO7IzSWn"
   },
   "source": [
    "## モデルの結果を比較\n",
    "|Model |Test score  |Test accuracy  |\n",
    "|---|---|---|\n",
    "|RNN |2.366 |0.3601 |\n",
    "|SimpleRNN |2.438 |0.3619 |\n",
    "|GRU |1.496 |0.6219 |\n",
    "|LSTM |2.428 |0.3619 |\n",
    "|SimpleRNNCell |2.439 |0.3619 |\n",
    "|GRUCell |1.496 |0.6219 |\n",
    "|LSTMCell |2.428 |0.3619 |\n",
    "|CuDNNGRU |1.576 |0.5939 |\n",
    "|CuDNNLSTM |2.426 |0.3619 |\n",
    "\n",
    "\n",
    "ロイターのデータセットをepoch３回に限定した結果でみると、GRU、GRUCell、次にCuDNNGRUと、GRU系の精度が最も良かった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4UvxLe3NIfOO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sprint23_lstm.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
