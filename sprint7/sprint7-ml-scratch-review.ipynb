{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習スクラッチの振り返り\n",
    "このスクールに入るまで、プログラミングの初心者であり、相当苦労した。一番の課題は今回のスクラッチの目的を理解しないまま進めたことであり、関数などの意味を理解していなかった点にあると思った。具体的には、どういう手順で進めればいいかの流れが、中々掴めなかった。対策としては、分析手法の関数の理解や、プログラミングの設計を紙に書いたりして、可視化することの必要性を感じた。\n",
    "\n",
    "次に、それをどのように表現するか（コーディング）に苦労した。コードの書き方（文法など）や、どうやってエラーを解消するかで詰まることが多かった。ネットで調べても分からず、基本的に止まっている時間が多かったように思う。対策としては、とにかく、調べたり、紙に書いたりして、手を動かすこと。調べても分からないことは、すぐに人に聞くことが大切だと感じた。また、最終手段としては、人からコードをもらって、それを見て、理解に努めること。あと中々時間を取れないが、完成後に写経して体に覚えこませることが必要だと感じた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価関係"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecallとPrecisionはどう違うか\n",
    "Precision（適合率）は、検索した結果に適合データ（正解となるデータ）がどれだけ含まれているかを示すものである。一方で、Recall（再現率)は、適合データ（正解となるデータ）全体のどれだけが検索結果に含まれているかを示すものである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1スコアとは何か\n",
    "一般に、再現率の高いシステムは適合率が低く、その逆に、適合率が高いシステムは再現率が低い傾向にある。評価指標が2つあると、どちらのシステムが優れているか比較が難しいので、再現率と適合率の調和平均を取った値をF１スコアという指標で性能を表すことがある。\n",
    "\n",
    "F１スコア = （2×適合率×再現率）/（適合率＋再現率）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC曲線とは何か\n",
    "ROC曲線とは、クラス分類のパフォーマンスを計測するための方法の一つであり、分類器が一般的にどう振る舞うかについて、より良い全体像を提供してくれる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バイアスとバリアンスのトレードオフとは\n",
    "バイアスとは、モデルと学習データの平均的なズレを表し、バリアンスは、モデルの複雑さの度合い（モデルの分散と等価）を表す。モデルが単純だと、性能は良くないが、教師データに対して安定（高バイアス・低バリアンス）、モデルが複雑だと、性能は良いが、教師データに対して不安定（過学習など）（低バイアス・高バリアンス）であるため、両者はトレードオフの関係にあると言える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 過学習を防ぐための方法を3つ以上説明する\n",
    "過学習を防ぐための方法として、正則化、ドロップアウト、K分割交差検証（クロスバリデーション）などがある。正則化とは、パラメータの値の大きさに対して何らかのペナルティを科すことで、過学習を抑えた「ちょうど良い」パラメータを学習させる方法である。ドロップアウトとは、ランダムにノードを非活性にして学習する」処理であり、回帰曲線で言えば、全プロットをもとに線を引く代わりに、ある程度間引いたプロットに対して回帰線を求めるような方法である。K分割交差検証とは、学習に利用するデータを k 分割して、k - 1 個のデータセットで学習し、残りの 1 個のデータセットで検証を行うという方法である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの汎用性を確認する方法は何か\n",
    "モデルの汎用性を確認する方法として、ホールドアウト法、交差検定（クロスバリデーション）、混合行列などがある。ホールドアウト法は、モデルを作る学習データ (Train Data)と、モデルを評価するテストデータ(Test Data)に分割して評価する。交差検定では、用意したデータを例えば５個に分けて、1回目はそのうちの一つをテストデータ、それ以外を学習データとして、学習・評価する。2回目は1回目と異なる別のデータをテストデータとして使い、3回目は1,2回目と異なるデータで評価する。そして、各回で測定した精度の平均を取る。混合行列は、正解率だけではなく、実際にどんな感じでモデルが判別されているか確認する方法である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手法関係"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習とは何か\n",
    "機械学習とは、特徴量とラベルの間の関係を確率的な「モデル」で表現し、多数のデータからその確率的なモデルの推定を行うために、機械に学習させること。\n",
    "基本的な流れは以下の通り。\n",
    "①自分の扱いたい問題に関するデータを集め、適切な形に前処理する。\n",
    "②前処理が終わった膨大な元の情報から予測のために必要な本質的な情報（特徴量）を抽出する。\n",
    "③予測のための機械学習の「モデル」を用意する。\n",
    "④データ（特徴量）を「モデル」に入力し学習をさせる。\n",
    "⑤学習済みのモデルの性能を評価する。\n",
    "⑥最後に、学習済みのモデルに未知のデータを入力し、予測をさせる。\n",
    "\n",
    "これらの手順はどれも非常に重要だが、機械学習では「特徴量の設計」と「モデルの選択」が特に重要である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習では何ができるのか\n",
    "機械学習では、人間が処理するには時間がかかりすぎる莫大なビッグデータを、自律的に瞬時に分析したり、未来を予測できたりすることが最大の利点である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手法によって異なるのはどういった部分か\n",
    "機械学習は、与えられるデータの種類によって「教師あり学習」と「教師なし学習」に分けられる。\n",
    "「教師あり学習」とは、特徴量（データ）とラベル（正解）の情報をどちらも与えて、予測するものである。\n",
    "一方で、特徴量のみを与える場合を「教師なし学習」という。したがって、自分で特徴量から対象のラベルの規則を見つける必要があります。そのため、「教師なし学習」のほうが「教師あり学習」よりも全般的に性能が劣る、もしくはデータの構造に関する何らかの仮定が必要だということが知られている。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 線形回帰が適しているデータや状況は何か\n",
    "線形回帰は、ラベルが、特徴量の線形和で表すことができるという仮定を置いているため、多数の特徴量を持つデータに対しては、線形回帰は非常に有効な手法となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ロジスティック回帰が適しているデータや状況は何か\n",
    "ロジスティック回帰が適しているのは、2つのデータ群は、だいたい分かれますが、集まってはいないとき、または、正規分布の仮定がないときに、「だいたい」というのを、確率を使って数値で表現できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVMが適しているデータや状況は何か\n",
    "SVM（サポートベクターマシン ）は、判別分析に適しており、正規分布していなくても大丈夫である。判別分析とは、2つのデータ群がそれぞれ空間内に集まっているイメージであり、 より正確に言えば、正規分布の山が２つあることを想定している。ロジスティック回帰分析との違いは、片方のデータ群の表れ方が0.5以上の領域がないと、エラーになることである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 決定木が適しているデータや状況は何か\n",
    "決定木は、データの特徴的な部分をざっくりと見ておきたい時に適している。結果のモデルが容易に可視化することが可能であり、データスケールに対して完全に不変であるという長所がある。個々の特徴量は独立に処理され、データの分割はスケールに依存しないので、決定木においては特徴量の正規化や標準化は必要ない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-meansが適しているデータや状況は何か\n",
    "K-meansは、正解ラベルのない「教師なし学習」で用いられる一般的な手法である。これは比較的理解しやすく実装しやすいからだけでなく、比較的高速に実行できるため、大規模なデータセットにも適用できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### これ以外にどのような機械学習手法があるか簡潔にまとめる\n",
    "ランダムフォレストとは、決定木を大量に生成し、各決定木の結果を集計して予測する手法。各決定木は独立しており、説明変数からのサンプリングまたは学習データからのサンプリングによって、異なる特性を持つように学習する。汎化性能が高く、処理の並列性も高いので人気のある手法である。勾配ブースティング木とは、決定木を大量に生成し、各決定木の結果を集計して予測する手法。決定木を逐次的に増やしていき、生成済みの決定木が間違えてしまうケースのラベルを更新して、新たな決定木を生成していく。XGBoostという高速なライブラリが出現し、精度が非常に高く計算時間も実用的な時間に収まるようになり、最も人気な手法である。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
