{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9lnFzLX9uwtk"
   },
   "source": [
    "## AIF_sprint24_seq2seq\n",
    "1.この課題の目的   \n",
    "RNNの活用例を知る   \n",
    "慣れていないフレームワークとの関わり方を知る   \n",
    "\n",
    "【目的としないこと】  \n",
    "手法の細かい部分への理解   \n",
    "新たなフレームワークへの詳しい理解  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 10442,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "USq0qaTruwtl",
    "outputId": "ac1a7490-733c-4975-c1b8-244ec2b61828"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-2cb836b1-b639-43e3-8b70-8958a9adb3f6\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-2cb836b1-b639-43e3-8b70-8958a9adb3f6\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving fra.txt to fra.txt\n",
      "Number of samples: 10000\n",
      "Number of unique input tokens: 69\n",
      "Number of unique output tokens: 93\n",
      "Max sequence length for inputs: 16\n",
      "Max sequence length for outputs: 59\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 0.9183 - val_loss: 0.9345\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.7319 - val_loss: 0.7925\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.6230 - val_loss: 0.6986\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.5654 - val_loss: 0.6446\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.5233 - val_loss: 0.6086\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.4923 - val_loss: 0.5709\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.4666 - val_loss: 0.5564\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.4455 - val_loss: 0.5350\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.4265 - val_loss: 0.5216\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.4097 - val_loss: 0.5082\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.3945 - val_loss: 0.4987\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.3804 - val_loss: 0.4898\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.3675 - val_loss: 0.4809\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.3550 - val_loss: 0.4788\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.3434 - val_loss: 0.4703\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.3326 - val_loss: 0.4670\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.3221 - val_loss: 0.4643\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.3121 - val_loss: 0.4601\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.3025 - val_loss: 0.4605\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.2936 - val_loss: 0.4499\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.2848 - val_loss: 0.4553\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.2762 - val_loss: 0.4578\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.2681 - val_loss: 0.4524\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.2606 - val_loss: 0.4609\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.2532 - val_loss: 0.4587\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.2458 - val_loss: 0.4574\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.2388 - val_loss: 0.4582\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.2326 - val_loss: 0.4631\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.2261 - val_loss: 0.4653\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.2199 - val_loss: 0.4711\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.2139 - val_loss: 0.4723\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.2081 - val_loss: 0.4714\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.2027 - val_loss: 0.4785\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1975 - val_loss: 0.4764\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1923 - val_loss: 0.4804\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1877 - val_loss: 0.4908\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1829 - val_loss: 0.4848\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1786 - val_loss: 0.4996\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1741 - val_loss: 0.4968\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1700 - val_loss: 0.5058\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1662 - val_loss: 0.5082\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1619 - val_loss: 0.5085\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1584 - val_loss: 0.5163\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1551 - val_loss: 0.5247\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1514 - val_loss: 0.5229\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1481 - val_loss: 0.5183\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1447 - val_loss: 0.5303\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1417 - val_loss: 0.5406\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1385 - val_loss: 0.5330\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1358 - val_loss: 0.5501\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1332 - val_loss: 0.5470\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1304 - val_loss: 0.5553\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1279 - val_loss: 0.5551\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1250 - val_loss: 0.5609\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1223 - val_loss: 0.5709\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1207 - val_loss: 0.5688\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1181 - val_loss: 0.5778\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1162 - val_loss: 0.5712\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1139 - val_loss: 0.5831\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1119 - val_loss: 0.5850\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1096 - val_loss: 0.5858\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1078 - val_loss: 0.5905\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.1057 - val_loss: 0.5935\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1043 - val_loss: 0.6059\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1024 - val_loss: 0.6095\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.1004 - val_loss: 0.6148\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0990 - val_loss: 0.6145\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0972 - val_loss: 0.6249\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0957 - val_loss: 0.6211\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0944 - val_loss: 0.6277\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0928 - val_loss: 0.6286\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0913 - val_loss: 0.6304\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0898 - val_loss: 0.6373\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0881 - val_loss: 0.6414\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0870 - val_loss: 0.6439\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0856 - val_loss: 0.6473\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0843 - val_loss: 0.6488\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0829 - val_loss: 0.6556\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0818 - val_loss: 0.6652\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0804 - val_loss: 0.6706\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0796 - val_loss: 0.6669\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0784 - val_loss: 0.6755\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0772 - val_loss: 0.6768\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0762 - val_loss: 0.6781\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0750 - val_loss: 0.6872\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0739 - val_loss: 0.6827\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0732 - val_loss: 0.6959\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0723 - val_loss: 0.6927\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0712 - val_loss: 0.7004\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0702 - val_loss: 0.6998\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0692 - val_loss: 0.7017\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0681 - val_loss: 0.7093\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0676 - val_loss: 0.7099\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0667 - val_loss: 0.7166\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0654 - val_loss: 0.7071\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0651 - val_loss: 0.7233\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0639 - val_loss: 0.7276\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0631 - val_loss: 0.7241\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0622 - val_loss: 0.7258\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 23s 3ms/step - loss: 0.0613 - val_loss: 0.7246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Va !\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Salut !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Cours !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Cours !\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Ça alors !\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Au feu !\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: À l'aide !\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Saute.\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attendez !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attendez !\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Poursuivens, je me place.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Poursuivens, je me place.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Poursuivens, je me place.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Salut !\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Salut !\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Je vous le fai.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: J'ai essayé.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Je l'ai emporté !\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Je l'ai emporté !\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: Oh non !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attaquez !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attaquez !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Merci !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Merci !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Merci !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Merci !\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Lève-toi.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Vas-y maintenant.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Vas-y maintenant.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Vas-y maintenant.\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Compris !\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Compris !\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: T'as capté ?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: T'as capté ?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: T'as capté ?\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Monte.\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Monte.\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Serre-moi dans tes bras !\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Serre-moi dans tes bras !\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je suis tombée.\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je suis tombée.\n",
      "\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: Je sais le fris.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je suis parti.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je suis parti.\n",
      "\n",
      "-\n",
      "Input sentence: I lost.\n",
      "Decoded sentence: J'ai perdu.\n",
      "\n",
      "-\n",
      "Input sentence: I'm 19.\n",
      "Decoded sentence: Je me suis amendé.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je suis fatigué !\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je suis fatigué !\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Écoutez !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: En aucun cas.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: En aucun cas.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: En aucun cas.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: En aucun cas.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: En aucun cas.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: En aucun cas.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: En aucun cas.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: En aucun cas.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: En aucun cas.\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Vraiment ?\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Vraiment ?\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Vraiment ?\n",
      "\n",
      "-\n",
      "Input sentence: Thanks.\n",
      "Decoded sentence: Merci !\n",
      "\n",
      "-\n",
      "Input sentence: We try.\n",
      "Decoded sentence: On essaye.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous l'avons emporté.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous l'avons emporté.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous l'avons emporté.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous l'avons emporté.\n",
      "\n",
      "-\n",
      "Input sentence: Ask Tom.\n",
      "Decoded sentence: Demande à Tom.\n",
      "\n",
      "-\n",
      "Input sentence: Awesome!\n",
      "Decoded sentence: Fantastique !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Soyez calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Soyez calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Soyez calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be cool.\n",
      "Decoded sentence: Soyez calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez justes !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez justes !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez justes !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez justes !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez justes !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez justes !\n",
      "\n",
      "-\n",
      "Input sentence: Be kind.\n",
      "Decoded sentence: Sois gentil.\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentille !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentille !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentille !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentille !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentille !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentille !\n",
      "\n",
      "-\n",
      "Input sentence: Beat it.\n",
      "Decoded sentence: Dégage !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Appelle-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Appelle-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: Appelle-nous !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: Appelle-nous !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entrez !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entrez !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entrez !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entrez !\n",
      "\n",
      "-\n",
      "Input sentence: Come on!\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Viens !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Sequence to sequence example in Keras (character-level).\n",
    "This script demonstrates how to implement a basic character-level\n",
    "sequence-to-sequence model. We apply it to translating\n",
    "short English sentences into short French sentences,\n",
    "character-by-character. Note that it is fairly unusual to\n",
    "do character-level machine translation, as word-level\n",
    "models are more common in this domain.\n",
    "# Summary of the algorithm\n",
    "- We start with input sequences from a domain (e.g. English sentences)\n",
    "    and corresponding target sequences from another domain\n",
    "    (e.g. French sentences).\n",
    "- An encoder LSTM turns input sequences to 2 state vectors\n",
    "    (we keep the last LSTM state and discard the outputs).\n",
    "- A decoder LSTM is trained to turn the target sequences into\n",
    "    the same sequence but offset by one timestep in the future,\n",
    "    a training process called \"teacher forcing\" in this context.\n",
    "    Is uses as initial state the state vectors from the encoder.\n",
    "    Effectively, the decoder learns to generate `targets[t+1...]`\n",
    "    given `targets[...t]`, conditioned on the input sequence.\n",
    "- In inference mode, when we want to decode unknown input sequences, we:\n",
    "    - Encode the input sequence into state vectors\n",
    "    - Start with a target sequence of size 1\n",
    "        (just the start-of-sequence character)\n",
    "    - Feed the state vectors and 1-char target sequence\n",
    "        to the decoder to produce predictions for the next character\n",
    "    - Sample the next character using these predictions\n",
    "        (we simply use argmax).\n",
    "    - Append the sampled character to the target sequence\n",
    "    - Repeat until we generate the end-of-sequence character or we\n",
    "        hit the character limit.\n",
    "# Data download\n",
    "English to French sentence pairs.\n",
    "http://www.manythings.org/anki/fra-eng.zip\n",
    "Lots of neat sentence pairs datasets can be found at:\n",
    "http://www.manythings.org/anki/\n",
    "# References\n",
    "- Sequence to Sequence Learning with Neural Networks\n",
    "    https://arxiv.org/abs/1409.3215\n",
    "- Learning Phrase Representations using\n",
    "    RNN Encoder-Decoder for Statistical Machine Translation\n",
    "    https://arxiv.org/abs/1406.1078\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = 'fra.txt'\n",
    "\n",
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "# Save model\n",
    "model.save('s2s.h5')\n",
    "\n",
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9hR3_Hfuwtr"
   },
   "source": [
    "## コードリーディング\n",
    "\n",
    "### 説明（サンプルコードの各部分がどういった役割かを読み取る）\n",
    "43から49行目 : ライブラリのimport    \n",
    "51から56行目 : ハイパーパラメータの設定      \n",
    "59から116行目 : 文字のシーケンスのベクトル化      \n",
    "119から123行目 : seq2seqモデルの構築（エンコーダ）     \n",
    "130から134行目 : seq2seqモデルの構築（デコーダ）      \n",
    "138から147行目 : モデルのコンパイル設定      \n",
    "158から169行目 : デコーダの実装     \n",
    "179から214行目 : モデルの予測に基づいて次の文字をサンプリングする関数      \n",
    "217から224行目 : テキスト生成ループ    \n",
    "\n",
    "### Seq2Seqは何をしているか\n",
    "Seq2Seqはエンコーダとデコーダの2つのモジュールで構成されている。     \n",
    "エンコーダはRNNを利用して、時系列データを隠れ状態ベクトルに変換する。ここでは、入力された単語から、次に出現する単語を確率的に選択する。RNNとしてはLSTMを利用しており、エンコーダが出力するベクトル、すなわちLSTMレイヤの最後の隠れ状態には、入力文章を翻訳するために必要な情報がエンコードされている。      \n",
    "エンコードでは、最後の隠れ状態は固定長のベクトルに変換している。また、最後の隠れ状態がエンコーダとデコーダの架け橋となっている。      \n",
    "デコーダでも、RNNを利用してエンコーダと同様のモデルであり、エンコードされた情報を文字に変換することによって、機械翻訳を行なっている。    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## イメージキャプショニングをシェルで実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "andoutakaakinoMacBook-ea:image_captioning andoutakaaki$ python sample.py --image='png/example.png'\n",
    "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /Users/andoutakaaki/.torch/models/resnet152-b121ed2d.pth\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 241530880/241530880 [00:04<00:00, 56435250.05it/s]\n",
    "<start> a group of giraffes standing next to each other . <end>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kerasで動かしたい場合はどうするか\n",
    "説明\n",
    "\n",
    "PyTorchによる実装を動かしたが、何らかの理由からKerasで動かしたい状況が考えられる。どういった手順を踏むことになるか調査し、できるだけ詳しく説明せよ。\n",
    "\n",
    "特に今回はPyTorchのための学習済みの重みをKerasで使えるようにしたいので、その点についてはしっかりと触れること。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 説明課題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 今回使用したSeq2Seqの実装を使い日本語と英語の翻訳を行いたい場合はどのような手順を踏むか\n",
    "・まず、リンクでつながっている例文同士が、互いに対訳関係にある例文が掲載されている日英の対訳データを入手し、対訳ペアのリストを作成する。       \n",
    "・次に、データの整形を行う。まず、日本語の単語の分割をする必要がある。そのために、mecabなどを利用して、形態素解析を行う。    \n",
    "・その上で、単語の正規化（大文字小文字）、Stemming処理（活用形の処理）を行なって、テキストを単語IDに変換する。     \n",
    "・次に、テキストからコンテキストとターゲットを作り、one-hot表現に変換するといった手順により、前処理を行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械翻訳のための発展的手法にはどういったものがあるか\n",
    "・機械翻訳の流れでみると、「ルールベースの翻訳」から「用例ベースの翻訳」へ、そして「統計ベースの翻訳」へと移り変わってきた。現在では、これらの従来の技術に代わり、ニューラル翻訳が多くの注目を集めている。Google翻訳では、2016年からニューラル翻訳が使われている。この機械翻訳システムは、GNMT（Google Neural Mashine Translation）と呼ばれ、翻訳精度向上のために多くの改良がなされている。             \n",
    "・また、並列化処理ができないRNNの欠点に対して、現在、RNNを取り除く研究（もしくは並列計算可能なRNNの研究）が活発に行われている。その中で有名なものに、Transformerと呼ばれるモデルがある。Transformerでは、Self-Attentionというテクニックが使われているのが特徴的である。      \n",
    "・また、DeepMindのチームによって行われた研究に、NMT（Neural Turing Machine）がある。NMTは、RNNの外側に情報を記憶しておくためのメモリ機能を配置し、Attention（２つの時系列データ間の対応関係をデータから学習する）を使って、そのメモリから必要な情報を読み書きさせる方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### イメージキャプショニングとは逆に文章から画像を生成する手法にはどういったものがあるか\n",
    "・Microsoftは、Generative Adversarial Network (GAN: 敵対的生成ネットワーク)を利用して、文章から画像を生成する人工知能技術を開発した。GANはGeneratorとDiscriminatorという別々の学習モデルを用いる。Generatorはできるだけ本物（オリジナル）に近い画像を生成し、Discriminatorはそれが本物の画像か否かを判定するような構造をしており、両方を競わせることで、より本物に近い画像などを生成することを目的としている。    \n",
    "・Microsoftは、GANを改良したAttentional GAN (AttnGAN)を開発しており、AttnGANでは、入力されたキャプションを個々の単語に分割し、それらの単語を画像の特定の領域とマッチングさせることで、人間のような描画を実現している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 異なるフレームワークに実装を移す場合にはどういった部分を気をつけるか\n",
    "・例えば、ディープラーニングで人気の高いKerasとPyTorchを比較してみる。    \n",
    "・Kerasは、一般的に使用されているレイヤとオペレーションをきちんとしたレゴサイズのビルディングブロックにまとめ、ディープラーニングの複雑さを抽象化し、コードの記述が簡潔で、使いやすい。一方、PyTorchは、ユーザーにカスタムレイヤーを書いたり数値最適化タスクのフードの下を見たりする自由を与えており、ネットワークの詳細設計をすることができる。        \n",
    "・すなわち、Kerasは読みやすくて簡潔であり、実装の詳細をスキップしながら最初のエンドツーエンドのディープラーニングモデルをより速く構築することを可能にする。ただし、他のライブラリに比べて細かい設定が隠匿されているため、デバッグの際、問題の原因となる正確な行を突き止めるのが難しくなる。    \n",
    "・一方で、PyTorchは、より冗長なフレームワークであるため、スクリプトの実行を1行ずつ追跡することができる。    \n",
    "・したがって、実装の上では、Kerasで比べ、PyTorchは自由度が高い分、ネットワークの詳細設計のためのモデル構築を行う必要がある。     "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sprint24-seq2seq.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
