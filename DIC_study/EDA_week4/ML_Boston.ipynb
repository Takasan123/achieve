{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 授業前課題　ボストン住宅価格　線形回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 線形回帰とは何か\n",
    "線形回帰とは、2つの変数をとった時、YをXの「関数」として説明できないかを見ることである。例えば、「平均気温」をX、「ビールの売上」をYとすると、YとXの間に何か定量的な法則がないかを探る発想である。 \n",
    "回帰分析は、蓄積されたデータから法則を読み取る、基本的なツール。2つの変数のうち、より結果に近いもの（目的変数）をY、原因に近いもの（説明変数）をXと置くと、Y＝aX＋b というシンプルな式に落とし込め、直感的に分かりやすく、a、bが数値として得られるので、具体的数値の形でYを予測することができる。  \n",
    "線形回帰は、連続値をとる目的変数を予測するために使用される。具体的に言うと、そのデータの特徴量の傾向をみて(座標上に線を書いて)、具体的な数字を出す（線上から割り出す）、予測するのが回帰である。  \n",
    "一方で、分類は、回帰とは違い具体的な数字を出すのではなく、与えられたクラスに分ける（ラベリングする）ことを目的としている。例えば、花弁の数をみて、少ないとパンジー、多いとたんぽぽのように、あらかじめ与えられたクラス（ここでは、パンジーとたんぽぽ）に分けることを分類という。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データを取得する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 取得データをDataFrameにする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 説明変数を'LSTAT'のみにする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単回帰と重回帰についての違いを記述せよ\n",
    "単回帰は、Yを説明する、おそらく無数にある要素のうち、一つ変数Xに代表させて説明しようとしている。\n",
    "メリットとしては、要素を絞り込んだことによるシンプルさ、メッセージの明確さであり、 ヒントになる異常値の発見がしやすい。例えば、経営者が、「このビジネスの本質（因果）は何か？」を考える、ときなどに使う。  \n",
    "一方で、重回帰は、事象を複数の変数で説明しようとしている。（通常のビジネス事象は、複数の要素が絡み合って発生しているので）より実態に近い予測式ができる。売上を予測したいマーケティング担当者や出店担当者など、より現場に近い人々が、実務に使う数字を予測したいときに使う。\n",
    "\n",
    "※head()メソッドなどを使用して、データを確認する。\n",
    "1.x.head()\n",
    "2.y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータに分割する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 決定係数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 決定係数とは何か記述せよ\n",
    "決定係数とは、回帰分析によって求められた目的変数の予測値が、実際の目的変数の値とどのくらい一致しているかを表している指標であり、以下の式で表される。  決定係数＝（平均から回帰式上の推計値までの距離の二乗の和）÷（平均から各点までの距離の二乗の和）  \n",
    "決定係数について解説すると、各点の値＝回帰式上の推計値＋回帰式の誤差（＝各点の値と回帰式上の推計値との差）と考えることが出来る。\n",
    "この場合の回帰式の誤差に関して、以下の式が成り立つことが証明されている。  \n",
    "（平均から各点までの距離の二乗の和） ＝（平均から回帰式上の推計値までの距離の二乗の和） ＋（回帰式上の誤差の二乗の和）  \n",
    "意味合いとしては、全変動 ＝ 回帰で説明できる変動 ＋ 回帰では説明できない変動  よって、決定係数とは、全変動 のうち、 回帰で説明できる変動 の占める割合 と言える。  最も説明変数が、目的変数を説明できる場合、決定係数は1に限りなく近づく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 決定係数をいかなる場合も信じても良いか記述せよ\n",
    "決定係数は説明変数の数が増えるほど1に近づくという性質を持っている。そのため、説明変数の数が多い場合には、この点を補正した自由度調整済み決定係数を使用する。  \n",
    "自由調整済み決定係数さえ高ければなんでもよい」という考え方は不適切である。分析を行うからにはその目的があり、検証したい仮説があるはずであるが、こうした目的や仮説とは一切関係ない変数を、決定係数が上がるからという理由だけで無秩序に分析に加えてしまうと、そのモデルは解釈が難しくなり当初の目的を果たせなくなる。  \n",
    "また、決定係数はあくまで「予測の当てはまりの良さ」を表す指標である。分析の目的が「ある変数の値を予測したい」の場合には適切な指標だが、「雨が降った日数がコンビニの月間の売上に影響があるかどうか知りたい」のように、ある変数の影響の有無が主眼であり予測は重視しない場合には、決定係数に注目することはあまり意味がないと言える。この場合には「雨が降った日数」という説明変数の回帰係数や、その係数に対する検定の結果（有意かどうか）にまず注目すべきである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2,3,4次式の回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次数が大きくなるとどうなるか記述せよ\n",
    "説明変数をXとして、次数を増やしていくと、一般に次式のように表すことができる。\n",
    "fθ(X) = θ0 + θ1X + θ2X2+ θ3X3 +・・・ + θn Xn　　　（ただし、Xの２乗をX2などと表す）\n",
    "次元を増やしていくと、メリットとしては、データにフィットしやすくなる。一方で、デメリットとしては、過学習が起きることが挙げられる。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重回帰について記述せよ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
